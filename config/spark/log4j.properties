# =============================================================================
# APACHE SPARK - LOG4J CONFIGURATION
# =============================================================================
# Configuração de logging para Apache Spark
# =============================================================================

# Set everything to be logged to the console
log4j.rootCategory=INFO, console

# =============================================================================
# CONSOLE APPENDER
# =============================================================================

log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# =============================================================================
# FILE APPENDER (opcional - para logs persistentes)
# =============================================================================

# Rolling file appender
log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=/opt/spark/logs/spark.log
log4j.appender.file.MaxFileSize=10MB
log4j.appender.file.MaxBackupIndex=10
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# =============================================================================
# SPARK CORE LOGGING LEVELS
# =============================================================================

# Spark root logger
log4j.logger.org.apache.spark=INFO

# Spark SQL
log4j.logger.org.apache.spark.sql=INFO

# Spark Streaming
log4j.logger.org.apache.spark.streaming=INFO

# Spark Scheduler
log4j.logger.org.apache.spark.scheduler=INFO

# Spark Storage
log4j.logger.org.apache.spark.storage=INFO

# Spark Executor
log4j.logger.org.apache.spark.executor=INFO

# Spark Deploy
log4j.logger.org.apache.spark.deploy=INFO

# Spark RPC
log4j.logger.org.apache.spark.rpc=WARN

# Spark Network
log4j.logger.org.apache.spark.network=WARN

# =============================================================================
# HADOOP LOGGING LEVELS
# =============================================================================

# Hadoop
log4j.logger.org.apache.hadoop=WARN

# Hadoop HDFS
log4j.logger.org.apache.hadoop.hdfs=WARN

# Hadoop MapReduce
log4j.logger.org.apache.hadoop.mapreduce=WARN

# Hadoop YARN
log4j.logger.org.apache.hadoop.yarn=WARN

# Hadoop Security
log4j.logger.org.apache.hadoop.security=WARN

# =============================================================================
# HIVE LOGGING LEVELS
# =============================================================================

# Hive
log4j.logger.org.apache.hive=WARN

# Hive MetaStore
log4j.logger.org.apache.hive.metastore=WARN

# Hive HiveServer2
log4j.logger.org.apache.hive.service=WARN

# =============================================================================
# PARQUET LOGGING LEVELS
# =============================================================================

# Parquet
log4j.logger.org.apache.parquet=ERROR

# Parquet cascading
log4j.logger.parquet=ERROR

# =============================================================================
# JETTY LOGGING LEVELS (Spark UI)
# =============================================================================

# Jetty
log4j.logger.org.eclipse.jetty=WARN

# Spark Jetty
log4j.logger.org.spark_project.jetty=WARN

# =============================================================================
# THRIFT SERVER LOGGING LEVELS
# =============================================================================

# Thrift
log4j.logger.org.apache.thrift=WARN

# =============================================================================
# AWS SDK LOGGING LEVELS (para S3/MinIO)
# =============================================================================

# AWS SDK
log4j.logger.com.amazonaws=WARN

# AWS S3
log4j.logger.com.amazonaws.services.s3=WARN

# AWS Auth
log4j.logger.com.amazonaws.auth=WARN

# AWS Request
log4j.logger.com.amazonaws.request=WARN

# =============================================================================
# THIRD-PARTY LIBRARIES
# =============================================================================

# Apache HTTP Client
log4j.logger.org.apache.http=WARN

# Apache Commons
log4j.logger.org.apache.commons=WARN

# Netty
log4j.logger.io.netty=WARN

# Curator (ZooKeeper client)
log4j.logger.org.apache.curator=WARN

# ZooKeeper
log4j.logger.org.apache.zookeeper=WARN

# Kafka (se usar Spark Streaming com Kafka)
log4j.logger.org.apache.kafka=WARN

# Akka (usado internamente pelo Spark)
log4j.logger.akka=WARN

# =============================================================================
# DRIVER LOGGING
# =============================================================================

# Settings to quiet third party logs that are too verbose
log4j.logger.org.spark_project.jetty=WARN
log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR

# =============================================================================
# REPL LOGGING (Spark Shell)
# =============================================================================

# REPL has separate logging configuration
log4j.logger.org.apache.spark.repl.Main=WARN

# =============================================================================
# METRICS LOGGING
# =============================================================================

# Metrics
log4j.logger.org.apache.spark.metrics=INFO

# =============================================================================
# SECURITY LOGGING
# =============================================================================

# Security
log4j.logger.org.apache.spark.security=WARN

# =============================================================================
# CUSTOM APPLICATION LOGGING
# =============================================================================

# SPTrans Pipeline custom loggers
log4j.logger.com.sptrans=INFO
log4j.logger.com.sptrans.ingestion=INFO
log4j.logger.com.sptrans.processing=INFO
log4j.logger.com.sptrans.serving=INFO

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================

# Para melhor performance, reduza logging em produção:
# log4j.rootCategory=WARN, console
# log4j.logger.org.apache.spark=WARN
# log4j.logger.org.apache.spark.sql=WARN

# Para debugging detalhado:
# log4j.rootCategory=DEBUG, console
# log4j.logger.org.apache.spark=DEBUG
# log4j.logger.org.apache.spark.sql.execution=DEBUG
# log4j.logger.org.apache.spark.sql.catalyst.optimizer=DEBUG

# =============================================================================
# STRUCTURED LOGGING (JSON format - opcional)
# =============================================================================

# Para usar JSON layout (requer log4j extras):
# log4j.appender.console.layout=org.apache.log4j.EnhancedPatternLayout
# log4j.appender.console.layout.ConversionPattern={"timestamp":"%d{ISO8601}","level":"%p","thread":"%t","logger":"%c","message":"%m"}%n

# =============================================================================
# APPENDER POR AMBIENTE
# =============================================================================

# Development
# log4j.rootCategory=DEBUG, console

# Staging
# log4j.rootCategory=INFO, console, file

# Production
# log4j.rootCategory=WARN, console, file

# =============================================================================
# SILENCE SPECIFIC WARNINGS
# =============================================================================

# Silence noisy warnings that are not useful
log4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR
log4j.logger.org.apache.hadoop.hdfs.DFSClient=ERROR
log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR

# =============================================================================
# ASYNC APPENDER (melhor performance - opcional)
# =============================================================================

# Uncomment para usar async appender:
# log4j.appender.async=org.apache.log4j.AsyncAppender
# log4j.appender.async.appenderRefs=console
# log4j.appender.async.blocking=false
# log4j.appender.async.bufferSize=1024

# =============================================================================
# NOTES
# =============================================================================

# Log Levels (do mais verboso ao menos):
# - ALL
# - TRACE
# - DEBUG
# - INFO
# - WARN
# - ERROR
# - FATAL
# - OFF

# Para aplicar mudanças:
# 1. Copie este arquivo para $SPARK_HOME/conf/log4j.properties
# 2. Ou especifique via --files no spark-submit:
#    spark-submit --files log4j.properties ...
# 3. Ou configure via --conf:
#    spark-submit --conf "spark.driver.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties" ...

# Para verificar configuração:
# - Verifique logs do driver e executors
# - Ajuste níveis conforme necessário
# - Em produção, use WARN ou ERROR para reduzir volume

# =============================================================================
# END
# =============================================================================
