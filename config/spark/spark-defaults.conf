# Spark Configuration for SPTrans Pipeline
# Delta Lake + MinIO (S3) Integration

# ==========================================
# SPARK CORE SETTINGS
# ==========================================
spark.master                     spark://spark-master:7077
spark.driver.memory              2g
spark.executor.memory            2g
spark.executor.cores             2
spark.sql.adaptive.enabled       true
spark.sql.adaptive.coalescePartitions.enabled true

# ==========================================
# DELTA LAKE CONFIGURATION
# ==========================================
spark.sql.extensions            io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.databricks.delta.retentionDurationCheck.enabled false
spark.databricks.delta.properties.defaults.enableChangeDataFeed true

# ==========================================
# S3 / MINIO CONFIGURATION
# ==========================================
spark.hadoop.fs.s3a.endpoint            http://minio:9000
spark.hadoop.fs.s3a.access.key          minioadmin
spark.hadoop.fs.s3a.secret.key          minioadmin123
spark.hadoop.fs.s3a.path.style.access   true
spark.hadoop.fs.s3a.impl                org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled false

# S3A Performance tuning
spark.hadoop.fs.s3a.block.size          32M
spark.hadoop.fs.s3a.buffer.dir          /tmp
spark.hadoop.fs.s3a.fast.upload         true
spark.hadoop.fs.s3a.multipart.size      100M
spark.hadoop.fs.s3a.multipart.threshold 50M
spark.hadoop.fs.s3a.threads.max         20

# ==========================================
# PARQUET CONFIGURATION
# ==========================================
spark.sql.parquet.compression.codec     snappy
spark.sql.parquet.mergeSchema           true
spark.sql.parquet.filterPushdown        true
spark.sql.parquet.writeLegacyFormat     false

# ==========================================
# PERFORMANCE TUNING
# ==========================================
spark.sql.shuffle.partitions            20
spark.default.parallelism               20
spark.sql.autoBroadcastJoinThreshold    10485760
spark.network.timeout                   800s
spark.executor.heartbeatInterval        60s

# ==========================================
# LOGGING
# ==========================================
spark.eventLog.enabled                  true
spark.eventLog.dir                      s3a://spark-logs/
spark.history.fs.logDirectory           s3a://spark-logs/

# ==========================================
# POSTGRESQL DRIVER
# ==========================================
spark.jars.packages                     io.delta:delta-core_2.12:2.4.0,org.apache.hadoop:hadoop-aws:3.3.4,org.postgresql:postgresql:42.6.0

# ==========================================
# MONITORING
# ==========================================
spark.metrics.conf.*.sink.prometheusServlet.class org.apache.spark.metrics.sink.PrometheusServlet
spark.metrics.conf.*.sink.prometheusServlet.path  /metrics/prometheus
spark.ui.prometheus.enabled                       true
