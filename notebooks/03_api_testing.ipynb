{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§ª Testes da API SPTrans - Tempo Real\n",
    "\n",
    "Este notebook realiza testes completos da API SPTrans em tempo real.\n",
    "\n",
    "## Objetivos\n",
    "1. Validar autenticaÃ§Ã£o e conectividade com a API\n",
    "2. Testar todos os endpoints disponÃ­veis\n",
    "3. Analisar estrutura e qualidade dos dados retornados\n",
    "4. Verificar performance e latÃªncia\n",
    "5. Detectar anomalias e inconsistÃªncias\n",
    "6. Documentar exemplos de resposta\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from typing import Dict, List, Optional\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ConfiguraÃ§Ãµes\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Carregar variÃ¡veis de ambiente\n",
    "load_dotenv('../.env')\n",
    "\n",
    "print(\"âœ… Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ConfiguraÃ§Ã£o da API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraÃ§Ãµes da API SPTrans\n",
    "API_TOKEN = os.getenv('SPTRANS_API_TOKEN', 'YOUR_TOKEN_HERE')\n",
    "BASE_URL = 'http://api.olhovivo.sptrans.com.br/v2.1'\n",
    "\n",
    "# Verificar token\n",
    "if API_TOKEN == 'YOUR_TOKEN_HERE':\n",
    "    print(\"âš ï¸ ATENÃ‡ÃƒO: Configure seu token da API SPTrans no arquivo .env\")\n",
    "    print(\"\\nPara obter um token:\")\n",
    "    print(\"1. Acesse: http://www.sptrans.com.br/desenvolvedores/\")\n",
    "    print(\"2. Cadastre-se e solicite um token de acesso\")\n",
    "    print(\"3. Adicione o token no arquivo .env: SPTRANS_API_TOKEN=seu_token_aqui\")\n",
    "else:\n",
    "    print(f\"âœ… Token configurado: {API_TOKEN[:10]}...{API_TOKEN[-10:]}\")\n",
    "    print(f\"âœ… Base URL: {BASE_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para interagir com a API\n",
    "class SPTransAPITester:\n",
    "    \"\"\"Classe para testar a API SPTrans\"\"\"\n",
    "    \n",
    "    def __init__(self, token: str, base_url: str):\n",
    "        self.token = token\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "        self.authenticated = False\n",
    "        self.test_results = []\n",
    "    \n",
    "    def authenticate(self) -> bool:\n",
    "        \"\"\"Autentica na API\"\"\"\n",
    "        url = f\"{self.base_url}/Login/Autenticar?token={self.token}\"\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = self.session.post(url)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            self.authenticated = response.text.lower() == 'true'\n",
    "            \n",
    "            result = {\n",
    "                'endpoint': 'Login/Autenticar',\n",
    "                'success': self.authenticated,\n",
    "                'status_code': response.status_code,\n",
    "                'latency_ms': round(elapsed * 1000, 2),\n",
    "                'response': response.text\n",
    "            }\n",
    "            self.test_results.append(result)\n",
    "            \n",
    "            return self.authenticated\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro na autenticaÃ§Ã£o: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def test_endpoint(self, endpoint: str, params: Optional[Dict] = None) -> Dict:\n",
    "        \"\"\"Testa um endpoint especÃ­fico\"\"\"\n",
    "        if not self.authenticated:\n",
    "            print(\"âš ï¸ NÃ£o autenticado! Execute authenticate() primeiro.\")\n",
    "            return None\n",
    "        \n",
    "        url = f\"{self.base_url}/{endpoint}\"\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = self.session.get(url, params=params)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            try:\n",
    "                data = response.json()\n",
    "            except:\n",
    "                data = response.text\n",
    "            \n",
    "            result = {\n",
    "                'endpoint': endpoint,\n",
    "                'success': response.status_code == 200,\n",
    "                'status_code': response.status_code,\n",
    "                'latency_ms': round(elapsed * 1000, 2),\n",
    "                'data_type': type(data).__name__,\n",
    "                'data_size': len(str(data)),\n",
    "                'response': data\n",
    "            }\n",
    "            \n",
    "            self.test_results.append(result)\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erro ao testar {endpoint}: {e}\")\n",
    "            return {'endpoint': endpoint, 'success': False, 'error': str(e)}\n",
    "    \n",
    "    def get_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Retorna resumo dos testes\"\"\"\n",
    "        df = pd.DataFrame(self.test_results)\n",
    "        return df[['endpoint', 'success', 'status_code', 'latency_ms']]\n",
    "\n",
    "# Inicializar tester\n",
    "api_tester = SPTransAPITester(API_TOKEN, BASE_URL)\n",
    "print(\"âœ… API Tester inicializado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Teste de AutenticaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” Testando autenticaÃ§Ã£o...\\n\")\n",
    "\n",
    "auth_success = api_tester.authenticate()\n",
    "\n",
    "if auth_success:\n",
    "    print(\"âœ… AutenticaÃ§Ã£o bem-sucedida!\")\n",
    "    print(f\"   Status: {api_tester.test_results[-1]['status_code']}\")\n",
    "    print(f\"   LatÃªncia: {api_tester.test_results[-1]['latency_ms']} ms\")\n",
    "else:\n",
    "    print(\"âŒ Falha na autenticaÃ§Ã£o!\")\n",
    "    print(\"\\nVerifique:\")\n",
    "    print(\"  1. Token estÃ¡ correto\")\n",
    "    print(\"  2. ConexÃ£o com a internet\")\n",
    "    print(\"  3. API SPTrans estÃ¡ disponÃ­vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Teste de Endpoints - Linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸšŒ Testando endpoints de LINHAS...\\n\")\n",
    "\n",
    "# 1. Buscar linhas\n",
    "print(\"1ï¸âƒ£ Buscar Linhas (termo: 'Centro')\")\n",
    "result = api_tester.test_endpoint('Linha/Buscar', params={'termosBusca': 'Centro'})\n",
    "if result and result['success']:\n",
    "    linhas = result['response']\n",
    "    print(f\"   âœ… Encontradas {len(linhas)} linhas\")\n",
    "    print(f\"   ğŸ“Š LatÃªncia: {result['latency_ms']} ms\")\n",
    "    if linhas:\n",
    "        print(f\"\\n   Exemplo de linha:\")\n",
    "        print(f\"   {json.dumps(linhas[0], indent=2, ensure_ascii=False)}\")\n",
    "else:\n",
    "    print(\"   âŒ Falha ao buscar linhas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# 2. Listar todas as linhas (se disponÃ­vel)\n",
    "print(\"2ï¸âƒ£ Listar Todas as Linhas\")\n",
    "result = api_tester.test_endpoint('Linha/Listar')\n",
    "if result and result['success']:\n",
    "    print(f\"   âœ… Total de linhas: {len(result['response'])}\")\n",
    "    print(f\"   ğŸ“Š LatÃªncia: {result['latency_ms']} ms\")\n",
    "else:\n",
    "    print(\"   â„¹ï¸ Endpoint nÃ£o disponÃ­vel ou sem dados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Teste de Endpoints - Paradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš Testando endpoints de PARADAS...\\n\")\n",
    "\n",
    "# 1. Buscar paradas\n",
    "print(\"1ï¸âƒ£ Buscar Paradas (termo: 'Paulista')\")\n",
    "result = api_tester.test_endpoint('Parada/Buscar', params={'termosBusca': 'Paulista'})\n",
    "if result and result['success']:\n",
    "    paradas = result['response']\n",
    "    print(f\"   âœ… Encontradas {len(paradas)} paradas\")\n",
    "    print(f\"   ğŸ“Š LatÃªncia: {result['latency_ms']} ms\")\n",
    "    if paradas:\n",
    "        print(f\"\\n   Exemplo de parada:\")\n",
    "        print(f\"   {json.dumps(paradas[0], indent=2, ensure_ascii=False)}\")\n",
    "else:\n",
    "    print(\"   âŒ Falha ao buscar paradas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# 2. Buscar paradas por corredor\n",
    "print(\"2ï¸âƒ£ Buscar Paradas por Corredor (cÃ³digo: 1)\")\n",
    "result = api_tester.test_endpoint('Parada/BuscarParadasPorCorredor', params={'codigoCorredor': 1})\n",
    "if result and result['success']:\n",
    "    print(f\"   âœ… Paradas encontradas no corredor\")\n",
    "    print(f\"   ğŸ“Š LatÃªncia: {result['latency_ms']} ms\")\n",
    "else:\n",
    "    print(\"   â„¹ï¸ Endpoint nÃ£o disponÃ­vel ou sem dados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Teste de Endpoints - PosiÃ§Ãµes em Tempo Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ Testando endpoints de POSIÃ‡Ã•ES EM TEMPO REAL...\\n\")\n",
    "\n",
    "# Buscar uma linha primeiro para testar posiÃ§Ãµes\n",
    "linhas_result = api_tester.test_endpoint('Linha/Buscar', params={'termosBusca': '8000'})\n",
    "\n",
    "if linhas_result and linhas_result['success'] and linhas_result['response']:\n",
    "    codigo_linha = linhas_result['response'][0].get('cl', None)\n",
    "    \n",
    "    if codigo_linha:\n",
    "        print(f\"1ï¸âƒ£ PosiÃ§Ãµes dos VeÃ­culos (Linha: {codigo_linha})\")\n",
    "        result = api_tester.test_endpoint('Posicao/Linha', params={'codigoLinha': codigo_linha})\n",
    "        \n",
    "        if result and result['success']:\n",
    "            data = result['response']\n",
    "            if isinstance(data, dict) and 'vs' in data:\n",
    "                veiculos = data['vs']\n",
    "                print(f\"   âœ… {len(veiculos)} veÃ­culos ativos\")\n",
    "                print(f\"   ğŸ“Š LatÃªncia: {result['latency_ms']} ms\")\n",
    "                print(f\"   ğŸ• HorÃ¡rio de referÃªncia: {data.get('hr', 'N/A')}\")\n",
    "                \n",
    "                if veiculos:\n",
    "                    print(f\"\\n   Exemplo de veÃ­culo:\")\n",
    "                    print(f\"   {json.dumps(veiculos[0], indent=2, ensure_ascii=False)}\")\n",
    "                    \n",
    "                    # Criar DataFrame para anÃ¡lise\n",
    "                    df_veiculos = pd.DataFrame(veiculos)\n",
    "                    print(f\"\\n   ğŸ“Š Resumo estatÃ­stico:\")\n",
    "                    print(f\"   - VeÃ­culos Ãºnicos: {df_veiculos['p'].nunique() if 'p' in df_veiculos.columns else 'N/A'}\")\n",
    "                    if 'py' in df_veiculos.columns and 'px' in df_veiculos.columns:\n",
    "                        print(f\"   - Lat mÃ©dia: {df_veiculos['py'].mean():.6f}\")\n",
    "                        print(f\"   - Lon mÃ©dia: {df_veiculos['px'].mean():.6f}\")\n",
    "            else:\n",
    "                print(\"   â„¹ï¸ Nenhum veÃ­culo ativo no momento\")\n",
    "        else:\n",
    "            print(\"   âŒ Falha ao buscar posiÃ§Ãµes\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ NÃ£o foi possÃ­vel obter cÃ³digo da linha\")\n",
    "else:\n",
    "    print(\"   âš ï¸ NÃ£o foi possÃ­vel buscar linhas para teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Teste de Endpoints - PrevisÃ£o de Chegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â° Testando endpoints de PREVISÃƒO DE CHEGADA...\\n\")\n",
    "\n",
    "# Buscar uma parada primeiro\n",
    "paradas_result = api_tester.test_endpoint('Parada/Buscar', params={'termosBusca': 'Paulista'})\n",
    "\n",
    "if paradas_result and paradas_result['success'] and paradas_result['response']:\n",
    "    codigo_parada = paradas_result['response'][0].get('cp', None)\n",
    "    \n",
    "    if codigo_parada:\n",
    "        print(f\"1ï¸âƒ£ PrevisÃ£o de Chegada (Parada: {codigo_parada})\")\n",
    "        result = api_tester.test_endpoint('Previsao/Parada', params={'codigoParada': codigo_parada})\n",
    "        \n",
    "        if result and result['success']:\n",
    "            data = result['response']\n",
    "            if isinstance(data, dict):\n",
    "                print(f\"   âœ… PrevisÃµes obtidas\")\n",
    "                print(f\"   ğŸ“Š LatÃªncia: {result['latency_ms']} ms\")\n",
    "                print(f\"   ğŸ• HorÃ¡rio: {data.get('hr', 'N/A')}\")\n",
    "                \n",
    "                if 'p' in data and 'l' in data['p']:\n",
    "                    linhas_previsao = data['p']['l']\n",
    "                    print(f\"   ğŸšŒ {len(linhas_previsao)} linhas com previsÃ£o\")\n",
    "                    \n",
    "                    if linhas_previsao:\n",
    "                        print(f\"\\n   Exemplo de previsÃ£o:\")\n",
    "                        print(f\"   {json.dumps(linhas_previsao[0], indent=2, ensure_ascii=False)}\")\n",
    "        else:\n",
    "            print(\"   âŒ Falha ao buscar previsÃµes\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ NÃ£o foi possÃ­vel obter cÃ³digo da parada\")\n",
    "else:\n",
    "    print(\"   âš ï¸ NÃ£o foi possÃ­vel buscar paradas para teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Teste de Endpoints - Corredores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ›£ï¸ Testando endpoints de CORREDORES...\\n\")\n",
    "\n",
    "print(\"1ï¸âƒ£ Listar Corredores\")\n",
    "result = api_tester.test_endpoint('Corredor')\n",
    "if result and result['success']:\n",
    "    corredores = result['response']\n",
    "    print(f\"   âœ… {len(corredores)} corredores encontrados\")\n",
    "    print(f\"   ğŸ“Š LatÃªncia: {result['latency_ms']} ms\")\n",
    "    \n",
    "    if corredores:\n",
    "        print(f\"\\n   Corredores disponÃ­veis:\")\n",
    "        for corredor in corredores[:5]:  # Primeiros 5\n",
    "            print(f\"   - {corredor}\")\n",
    "else:\n",
    "    print(\"   â„¹ï¸ Endpoint nÃ£o disponÃ­vel ou sem dados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ AnÃ¡lise de Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo dos testes\n",
    "summary_df = api_tester.get_summary()\n",
    "\n",
    "print(\"ğŸ“Š RESUMO DOS TESTES\")\n",
    "print(\"=\" * 60)\n",
    "display(summary_df)\n",
    "\n",
    "# EstatÃ­sticas\n",
    "total_tests = len(summary_df)\n",
    "successful_tests = summary_df['success'].sum()\n",
    "avg_latency = summary_df['latency_ms'].mean()\n",
    "max_latency = summary_df['latency_ms'].max()\n",
    "min_latency = summary_df['latency_ms'].min()\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ESTATÃSTICAS:\")\n",
    "print(f\"  - Testes executados: {total_tests}\")\n",
    "print(f\"  - Testes bem-sucedidos: {successful_tests} ({successful_tests/total_tests*100:.1f}%)\")\n",
    "print(f\"  - LatÃªncia mÃ©dia: {avg_latency:.2f} ms\")\n",
    "print(f\"  - LatÃªncia mÃ­nima: {min_latency:.2f} ms\")\n",
    "print(f\"  - LatÃªncia mÃ¡xima: {max_latency:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GrÃ¡fico de latÃªncias\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# LatÃªncias por endpoint\n",
    "summary_df.plot(x='endpoint', y='latency_ms', kind='bar', ax=axes[0], color='steelblue', legend=False)\n",
    "axes[0].set_title('LatÃªncia por Endpoint', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Endpoint')\n",
    "axes[0].set_ylabel('LatÃªncia (ms)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Taxa de sucesso\n",
    "success_counts = summary_df['success'].value_counts()\n",
    "axes[1].pie(success_counts.values, labels=['Sucesso', 'Falha'], autopct='%1.1f%%', \n",
    "            colors=['lightgreen', 'lightcoral'], startangle=90)\n",
    "axes[1].set_title('Taxa de Sucesso dos Testes', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ AnÃ¡lise de Qualidade dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… ANÃLISE DE QUALIDADE DOS DADOS DA API\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "quality_checks = []\n",
    "\n",
    "for test in api_tester.test_results:\n",
    "    if test.get('success') and 'response' in test:\n",
    "        data = test['response']\n",
    "        \n",
    "        check = {\n",
    "            'endpoint': test['endpoint'],\n",
    "            'has_data': len(str(data)) > 0,\n",
    "            'data_type': type(data).__name__,\n",
    "            'is_empty': len(data) == 0 if isinstance(data, (list, dict)) else False\n",
    "        }\n",
    "        \n",
    "        # VerificaÃ§Ãµes especÃ­ficas\n",
    "        if isinstance(data, list) and len(data) > 0:\n",
    "            check['count'] = len(data)\n",
    "            check['sample'] = data[0] if data else None\n",
    "        elif isinstance(data, dict):\n",
    "            check['keys'] = list(data.keys())\n",
    "        \n",
    "        quality_checks.append(check)\n",
    "\n",
    "# Exibir anÃ¡lise\n",
    "for check in quality_checks:\n",
    "    print(f\"\\nğŸ“‹ {check['endpoint']}:\")\n",
    "    print(f\"   - Tipo: {check['data_type']}\")\n",
    "    print(f\"   - Possui dados: {'âœ…' if check['has_data'] else 'âŒ'}\")\n",
    "    if 'count' in check:\n",
    "        print(f\"   - Quantidade: {check['count']}\")\n",
    "    if 'keys' in check:\n",
    "        print(f\"   - Chaves: {check['keys']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Teste de Stress - MÃºltiplas RequisiÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âš¡ TESTE DE STRESS - MÃºltiplas RequisiÃ§Ãµes Sequenciais\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fazer 10 requisiÃ§Ãµes seguidas\n",
    "n_requests = 10\n",
    "stress_results = []\n",
    "\n",
    "print(f\"\\nExecutando {n_requests} requisiÃ§Ãµes...\\n\")\n",
    "\n",
    "for i in range(n_requests):\n",
    "    start = time.time()\n",
    "    result = api_tester.test_endpoint('Linha/Buscar', params={'termosBusca': 'Centro'})\n",
    "    elapsed = (time.time() - start) * 1000\n",
    "    \n",
    "    stress_results.append({\n",
    "        'request': i + 1,\n",
    "        'success': result['success'] if result else False,\n",
    "        'latency_ms': elapsed\n",
    "    })\n",
    "    \n",
    "    print(f\"  Request {i+1}/{n_requests}: {'âœ…' if result and result['success'] else 'âŒ'} ({elapsed:.2f} ms)\")\n",
    "    time.sleep(0.5)  # Pequeno delay entre requisiÃ§Ãµes\n",
    "\n",
    "# AnÃ¡lise\n",
    "stress_df = pd.DataFrame(stress_results)\n",
    "\n",
    "print(f\"\\nğŸ“Š RESULTADOS DO TESTE DE STRESS:\")\n",
    "print(f\"  - Taxa de sucesso: {stress_df['success'].sum()}/{n_requests} ({stress_df['success'].sum()/n_requests*100:.1f}%)\")\n",
    "print(f\"  - LatÃªncia mÃ©dia: {stress_df['latency_ms'].mean():.2f} ms\")\n",
    "print(f\"  - LatÃªncia mÃ­nima: {stress_df['latency_ms'].min():.2f} ms\")\n",
    "print(f\"  - LatÃªncia mÃ¡xima: {stress_df['latency_ms'].max():.2f} ms\")\n",
    "print(f\"  - Desvio padrÃ£o: {stress_df['latency_ms'].std():.2f} ms\")\n",
    "\n",
    "# GrÃ¡fico\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(stress_df['request'], stress_df['latency_ms'], marker='o', linewidth=2, markersize=8)\n",
    "plt.axhline(y=stress_df['latency_ms'].mean(), color='r', linestyle='--', label=f'MÃ©dia: {stress_df[\"latency_ms\"].mean():.2f} ms')\n",
    "plt.title('LatÃªncia ao Longo das RequisiÃ§Ãµes - Teste de Stress', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('NÃºmero da RequisiÃ§Ã£o')\n",
    "plt.ylabel('LatÃªncia (ms)')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Exportar RelatÃ³rio de Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar relatÃ³rio completo\n",
    "report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'summary': {\n",
    "        'total_tests': total_tests,\n",
    "        'successful_tests': int(successful_tests),\n",
    "        'success_rate': float(successful_tests/total_tests*100),\n",
    "        'avg_latency_ms': float(avg_latency),\n",
    "        'min_latency_ms': float(min_latency),\n",
    "        'max_latency_ms': float(max_latency)\n",
    "    },\n",
    "    'test_results': api_tester.test_results,\n",
    "    'stress_test': stress_results,\n",
    "    'quality_checks': quality_checks\n",
    "}\n",
    "\n",
    "# Salvar relatÃ³rio\n",
    "report_path = '../data/samples/api_test_report.json'\n",
    "Path(report_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"âœ… RelatÃ³rio salvo em: {report_path}\")\n",
    "\n",
    "# Salvar resumo em CSV\n",
    "csv_path = '../data/samples/api_test_summary.csv'\n",
    "summary_df.to_csv(csv_path, index=False)\n",
    "print(f\"âœ… Resumo CSV salvo em: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ConclusÃµes e RecomendaÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ CONCLUSÃ•ES E RECOMENDAÃ‡Ã•ES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "conclusions = []\n",
    "\n",
    "# AnÃ¡lise de performance\n",
    "if avg_latency < 500:\n",
    "    conclusions.append(\"âœ… Performance excelente: latÃªncia mÃ©dia abaixo de 500ms\")\n",
    "elif avg_latency < 1000:\n",
    "    conclusions.append(\"âš ï¸ Performance boa: latÃªncia mÃ©dia entre 500-1000ms\")\n",
    "else:\n",
    "    conclusions.append(\"âŒ Performance preocupante: latÃªncia mÃ©dia acima de 1000ms\")\n",
    "\n",
    "# AnÃ¡lise de confiabilidade\n",
    "success_rate = (successful_tests/total_tests*100)\n",
    "if success_rate >= 95:\n",
    "    conclusions.append(\"âœ… Alta confiabilidade: taxa de sucesso >= 95%\")\n",
    "elif success_rate >= 80:\n",
    "    conclusions.append(\"âš ï¸ Confiabilidade moderada: taxa de sucesso entre 80-95%\")\n",
    "else:\n",
    "    conclusions.append(\"âŒ Baixa confiabilidade: taxa de sucesso < 80%\")\n",
    "\n",
    "# RecomendaÃ§Ãµes\n",
    "recommendations = [\n",
    "    \"ğŸ“Œ Implementar retry logic para requisiÃ§Ãµes falhadas\",\n",
    "    \"ğŸ“Œ Adicionar circuit breaker para proteÃ§Ã£o contra falhas\",\n",
    "    \"ğŸ“Œ Implementar cache para reduzir carga na API\",\n",
    "    \"ğŸ“Œ Monitorar latÃªncia e taxa de erro em produÃ§Ã£o\",\n",
    "    \"ğŸ“Œ Considerar rate limiting para evitar sobrecarga\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“Š ConclusÃµes:\")\n",
    "for conclusion in conclusions:\n",
    "    print(f\"  {conclusion}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ RecomendaÃ§Ãµes:\")\n",
    "for rec in recommendations:\n",
    "    print(f\"  {rec}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… Testes da API concluÃ­dos com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
