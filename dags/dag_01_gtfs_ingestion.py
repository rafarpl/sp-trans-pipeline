"""
Airflow DAG: IngestÃ£o GTFS (DiÃ¡ria).

Executa download e ingestÃ£o dos dados estÃ¡ticos GTFS
da SPTrans para a camada Bronze.

Schedule: DiÃ¡rio Ã s 02:00 (horÃ¡rio que SPTrans atualiza GTFS)
"""

from datetime import datetime, timedelta

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.slack.operators.slack_webhook import SlackWebhookOperator
from airflow.utils.task_group import TaskGroup

# Imports do projeto
import sys
sys.path.append('/opt/airflow/src')

from src.processing.jobs.ingest_gtfs_to_bronze import run_gtfs_to_bronze_job
from src.common.logging_config import setup_logging

# Setup logging
setup_logging(log_level="INFO", log_format="json")

# ConfiguraÃ§Ã£o padrÃ£o
default_args = {
    'owner': 'sptrans-pipeline',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email': ['alerts@sptrans-pipeline.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'execution_timeout': timedelta(minutes=30),
}

# DAG
dag = DAG(
    'sptrans_01_gtfs_ingestion',
    default_args=default_args,
    description='IngestÃ£o diÃ¡ria de dados GTFS estÃ¡ticos',
    schedule_interval='0 2 * * *',  # DiÃ¡rio Ã s 02:00
    catchup=False,
    max_active_runs=1,
    tags=['sptrans', 'bronze', 'gtfs', 'daily'],
)


def check_gtfs_availability(**context):
    """Verifica se GTFS estÃ¡ disponÃ­vel para download."""
    import requests
    from src.common.constants import SPTRANS_GTFS_URL
    
    try:
        response = requests.head(SPTRANS_GTFS_URL, timeout=10)
        if response.status_code == 200:
            print("âœ… GTFS available for download")
            return True
        else:
            raise Exception(f"GTFS not available: {response.status_code}")
    except Exception as e:
        print(f"âŒ Error checking GTFS availability: {e}")
        raise


def ingest_gtfs_to_bronze(**context):
    """Executa ingestÃ£o GTFS para Bronze."""
    # ForÃ§ar download apenas Ã s segundas-feiras (dados atualizam semanalmente)
    execution_date = context['execution_date']
    force_download = execution_date.weekday() == 0  # Segunda-feira = 0
    
    print(f"ðŸ”„ Starting GTFS ingestion (force_download={force_download})")
    
    stats = run_gtfs_to_bronze_job(force_download=force_download)
    
    print(f"âœ… GTFS ingestion completed successfully")
    print(f"ðŸ“Š Stats: {stats}")
    
    # Salvar stats no XCom para prÃ³ximas tasks
    context['task_instance'].xcom_push(key='gtfs_stats', value=stats)
    
    return stats


def validate_gtfs_data(**context):
    """Valida dados GTFS ingeridos."""
    stats = context['task_instance'].xcom_pull(
        task_ids='ingest_gtfs', 
        key='gtfs_stats'
    )
    
    print("ðŸ” Validating GTFS data")
    
    # ValidaÃ§Ãµes bÃ¡sicas
    if stats['failed_files'] > 0:
        raise Exception(f"âŒ {stats['failed_files']} files failed to process")
    
    if stats['total_records'] == 0:
        raise Exception("âŒ No records ingested")
    
    # Verificar arquivos mÃ­nimos obrigatÃ³rios
    required_files = ['stops', 'routes', 'trips', 'stop_times']
    results = stats.get('results_by_file', {})
    
    for req_file in required_files:
        if req_file not in results:
            raise Exception(f"âŒ Required file missing: {req_file}")
        
        if results[req_file].get('status') != 'success':
            raise Exception(f"âŒ File {req_file} failed to process")
        
        if results[req_file].get('record_count', 0) == 0:
            raise Exception(f"âŒ File {req_file} has zero records")
    
    print("âœ… GTFS data validation passed")
    return True


def send_success_notification(**context):
    """Envia notificaÃ§Ã£o de sucesso."""
    stats = context['task_instance'].xcom_pull(
        task_ids='ingest_gtfs',
        key='gtfs_stats'
    )
    
    message = f"""
    âœ… *GTFS Ingestion Successful*
    
    ðŸ“Š *Statistics:*
    â€¢ Files processed: {stats['total_files_processed']}
    â€¢ Total records: {stats['total_records']:,}
    â€¢ Success: {stats['successful_files']}
    â€¢ Failed: {stats['failed_files']}
    
    ðŸ• *Execution:* {context['execution_date'].strftime('%Y-%m-%d %H:%M:%S')}
    """
    
    print(message)
    return message


def send_failure_notification(**context):
    """Envia notificaÃ§Ã£o de falha."""
    exception = context.get('exception')
    
    message = f"""
    âŒ *GTFS Ingestion Failed*
    
    ðŸ”¥ *Error:* {str(exception)}
    
    ðŸ• *Execution:* {context['execution_date'].strftime('%Y-%m-%d %H:%M:%S')}
    
    ðŸ“‹ *DAG:* {context['dag'].dag_id}
    ðŸ“ *Task:* {context['task'].task_id}
    """
    
    print(message)
    return message


# Tasks
with dag:
    # 1. Verificar disponibilidade
    check_availability = PythonOperator(
        task_id='check_gtfs_availability',
        python_callable=check_gtfs_availability,
        provide_context=True,
    )
    
    # 2. Ingerir GTFS
    ingest_gtfs = PythonOperator(
        task_id='ingest_gtfs',
        python_callable=ingest_gtfs_to_bronze,
        provide_context=True,
    )
    
    # 3. Validar dados
    validate_data = PythonOperator(
        task_id='validate_gtfs_data',
        python_callable=validate_gtfs_data,
        provide_context=True,
    )
    
    # 4. NotificaÃ§Ã£o de sucesso
    success_notification = PythonOperator(
        task_id='send_success_notification',
        python_callable=send_success_notification,
        provide_context=True,
        trigger_rule='all_success',
    )
    
    # 5. NotificaÃ§Ã£o de falha
    failure_notification = PythonOperator(
        task_id='send_failure_notification',
        python_callable=send_failure_notification,
        provide_context=True,
        trigger_rule='one_failed',
    )
    
    # Fluxo
    check_availability >> ingest_gtfs >> validate_data >> success_notification
    [check_availability, ingest_gtfs, validate_data] >> failure_notification
