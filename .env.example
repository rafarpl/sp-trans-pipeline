# ============================================================================
# SPTRANS PIPELINE - ENVIRONMENT VARIABLES
# ============================================================================
# Template de variáveis de ambiente
# 
# Instruções:
# 1. Copie este arquivo para .env: cp .env.example .env
# 2. Preencha os valores das variáveis
# 3. NUNCA commite o arquivo .env (ele está no .gitignore)
# ============================================================================

# ============================================================================
# ENVIRONMENT
# ============================================================================
ENV=development  # development, staging, production

# ============================================================================
# SPTRANS API
# ============================================================================
# Token de autenticação da API Olho Vivo SPTrans
# Obtenha em: https://www.sptrans.com.br/desenvolvedores/
SPTRANS_API_TOKEN=seu_token_aqui

# URL base da API
SPTRANS_API_BASE_URL=http://api.olhovivo.sptrans.com.br/v2.1

# Timeout para requisições (segundos)
SPTRANS_API_TIMEOUT=30

# Retry settings
SPTRANS_API_MAX_RETRIES=3
SPTRANS_API_RETRY_DELAY=5

# ============================================================================
# MINIO (DATA LAKE)
# ============================================================================
# MinIO é usado como Data Lake (S3-compatible)

MINIO_ENDPOINT=http://minio:9000
MINIO_EXTERNAL_ENDPOINT=http://localhost:9000  # Para acesso externo
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=miniopassword123

# Bucket principal
MINIO_BUCKET=sptrans-datalake

# Paths das camadas
BRONZE_LAYER_PATH=s3a://sptrans-datalake/bronze
SILVER_LAYER_PATH=s3a://sptrans-datalake/silver
GOLD_LAYER_PATH=s3a://sptrans-datalake/gold

# ============================================================================
# POSTGRESQL
# ============================================================================
# Banco de dados principal (Airflow + Serving Layer)

POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=airflow
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow123

# Connection pool
POSTGRES_POOL_SIZE=10
POSTGRES_MAX_OVERFLOW=20

# ============================================================================
# AIRFLOW
# ============================================================================
# Apache Airflow configuration

# Executor (LocalExecutor, CeleryExecutor, KubernetesExecutor)
AIRFLOW_EXECUTOR=LocalExecutor

# Webserver
AIRFLOW_WEBSERVER_PORT=8080
AIRFLOW_WEBSERVER_WORKERS=4

# Admin user
AIRFLOW_ADMIN_USERNAME=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_ADMIN_EMAIL=admin@sptrans-pipeline.com

# Fernet key (para criptografia de senhas)
# Gere com: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW_FERNET_KEY=sua_fernet_key_aqui

# Secret key
AIRFLOW_SECRET_KEY=sua_secret_key_aqui

# ============================================================================
# SPARK
# ============================================================================
# Apache Spark configuration

SPARK_MASTER_URL=spark://spark-master:7077
SPARK_MASTER_PORT=7077
SPARK_MASTER_WEBUI_PORT=8081

# Workers
SPARK_WORKER_CORES=2
SPARK_WORKER_MEMORY=4g
SPARK_WORKER_INSTANCES=2

# Driver
SPARK_DRIVER_MEMORY=2g
SPARK_EXECUTOR_MEMORY=4g

# ============================================================================
# REDIS
# ============================================================================
# Redis para cache e fila do Celery

REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# Celery (se usar CeleryExecutor)
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=db+postgresql://airflow:airflow123@postgres:5432/airflow

# ============================================================================
# PROMETHEUS
# ============================================================================
# Monitoring and metrics

PROMETHEUS_PORT=9090
PROMETHEUS_RETENTION_TIME=30d

# Exporters
NODE_EXPORTER_PORT=9100
POSTGRES_EXPORTER_PORT=9187
REDIS_EXPORTER_PORT=9121

# ============================================================================
# GRAFANA
# ============================================================================
# Dashboards and visualization

GRAFANA_PORT=3000
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin

# ============================================================================
# SUPERSET
# ============================================================================
# Apache Superset for BI dashboards

SUPERSET_PORT=8088
SUPERSET_ADMIN_USERNAME=admin
SUPERSET_ADMIN_PASSWORD=admin
SUPERSET_ADMIN_EMAIL=admin@sptrans-pipeline.com

# Secret key
# Gere com: openssl rand -base64 42
SUPERSET_SECRET_KEY=sua_superset_secret_key_aqui

# ============================================================================
# JUPYTER
# ============================================================================
# Jupyter Lab for analysis

JUPYTER_PORT=8888
JUPYTER_TOKEN=sptrans-jupyter-token

# ============================================================================
# LOGGING
# ============================================================================
# Logging configuration

LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=json  # json, text

# Log retention
LOG_RETENTION_DAYS=30

# ============================================================================
# DATA PROCESSING
# ============================================================================

# Batch sizes
SPARK_BATCH_SIZE=10000
POSTGRES_BATCH_SIZE=1000

# Partitions
SPARK_SHUFFLE_PARTITIONS=200

# Lookback window (hours)
LOOKBACK_HOURS=24

# ============================================================================
# DATA QUALITY
# ============================================================================

# Thresholds
DATA_QUALITY_MIN_SCORE=80.0
COORDINATE_VALIDATION_STRICT=true

# São Paulo boundaries
SP_LAT_MIN=-24.0
SP_LAT_MAX=-23.3
SP_LON_MIN=-46.9
SP_LON_MAX=-46.3

# ============================================================================
# SCHEDULING
# ============================================================================

# Cron schedules (formato: min hour day month weekday)
GTFS_SCHEDULE="0 2 * * *"           # Daily at 2 AM
API_SCHEDULE="*/2 * * * *"           # Every 2 minutes
BRONZE_TO_SILVER_SCHEDULE="*/30 * * * *"  # Every 30 minutes
SILVER_TO_GOLD_SCHEDULE="0 * * * *"       # Every hour
GOLD_TO_SERVING_SCHEDULE="15 * * * *"     # Every hour at :15

# ============================================================================
# ALERTS
# ============================================================================

# Email alerts
ALERT_EMAIL_ENABLED=false
ALERT_EMAIL_FROM=alerts@sptrans-pipeline.com
ALERT_EMAIL_TO=admin@sptrans-pipeline.com

# SMTP configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASSWORD=your-app-password
SMTP_USE_TLS=true

# Slack alerts (opcional)
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
SLACK_CHANNEL=#sptrans-alerts

# ============================================================================
# BACKUP
# ============================================================================

# Backup configuration
BACKUP_ENABLED=true
BACKUP_RETENTION_DAYS=7
BACKUP_PATH=./data/backups

# ============================================================================
# GEOCODING
# ============================================================================

# Google Geocoding API (opcional)
GOOGLE_GEOCODING_API_KEY=your_google_api_key_here
GEOCODING_ENABLED=false

# ============================================================================
# FEATURES FLAGS
# ============================================================================

# Enable/disable features
ENABLE_REAL_TIME_INGESTION=true
ENABLE_GTFS_INGESTION=true
ENABLE_GEOCODING=false
ENABLE_ML_PREDICTIONS=false
ENABLE_STREAMING=false

# ============================================================================
# DEVELOPMENT
# ============================================================================

# Debug mode
DEBUG=false

# Hot reload (development)
HOT_RELOAD=false

# Sample data mode
USE_SAMPLE_DATA=false

# ============================================================================
# PERFORMANCE
# ============================================================================

# Parallelism
AIRFLOW_PARALLELISM=32
AIRFLOW_DAG_CONCURRENCY=16
AIRFLOW_MAX_ACTIVE_RUNS_PER_DAG=3

# Timeouts
DEFAULT_TASK_TIMEOUT=3600  # seconds
API_TIMEOUT=30
DB_TIMEOUT=30

# ============================================================================
# SECURITY
# ============================================================================

# Enable authentication
ENABLE_AUTH=true

# CORS (API)
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# Rate limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_PER_MINUTE=60

# ============================================================================
# MONITORING
# ============================================================================

# Health check intervals
HEALTH_CHECK_INTERVAL=60  # seconds

# Metrics collection
METRICS_ENABLED=true
METRICS_PORT=8000

# ============================================================================
# TESTING
# ============================================================================

# Test mode
TEST_MODE=false
TEST_DB=test_database

# ============================================================================
# NOTES
# ============================================================================

# IMPORTANT:
# - Never commit the .env file with real credentials
# - Keep .env.example updated with new variables
# - Use strong passwords in production
# - Rotate credentials regularly
# - Use secrets management in production (Vault, AWS Secrets Manager, etc)

# ============================================================================
# END
# ============================================================================
