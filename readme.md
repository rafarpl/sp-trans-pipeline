# üöå SPTrans Real-Time Data Pipeline

> **Projeto de Conclus√£o - P√≥s-Gradua√ß√£o em Engenharia de Dados**  
> **FIA/LABDATA - 2025**

Pipeline completo de dados para monitoramento em tempo real do sistema de transporte p√∫blico de S√£o Paulo, processando posi√ß√µes de ~15.000 √¥nibus a cada 2 minutos, com ingest√£o, processamento distribu√≠do e visualiza√ß√£o de KPIs operacionais.

---

## üìã √çndice

- [Vis√£o Geral](#-vis√£o-geral)
- [Arquitetura](#-arquitetura)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Pr√©-requisitos](#-pr√©-requisitos)
- [Instala√ß√£o](#-instala√ß√£o)
- [Configura√ß√£o](#-configura√ß√£o)
- [Uso](#-uso)
- [Dashboards e KPIs](#-dashboards-e-kpis)
- [Testes](#-testes)
- [Monitoramento](#-monitoramento)
- [Troubleshooting](#-troubleshooting)
- [Contribuindo](#-contribuindo)
- [Licen√ßa](#-licen√ßa)

---

## üéØ Vis√£o Geral

### Objetivo

Criar um produto de dados em **near real-time** que possibilite m√©tricas, KPIs, monitoramento e acompanhamento dos √¥nibus em circula√ß√£o no sistema p√∫blico de transporte da cidade de S√£o Paulo.

### Funcionalidades Principais

- ‚úÖ **Ingest√£o em Near Real-Time**: Coleta posi√ß√µes de todos os √¥nibus a cada 2 minutos via API SPTrans Olho Vivo
- ‚úÖ **Processamento Distribu√≠do**: Apache Spark para transforma√ß√£o e agrega√ß√£o de dados massivos
- ‚úÖ **Data Lake Multi-Camada**: Bronze (raw), Silver (cleaned), Gold (aggregated) com Delta Lake
- ‚úÖ **Enriquecimento de Dados**: Cruzamento com GTFS + geocoding reverso (lat/long ‚Üí endere√ßo)
- ‚úÖ **KPIs Operacionais**: Velocidade m√©dia, headway, pontualidade, cobertura de frota
- ‚úÖ **Orquestra√ß√£o Robusta**: Apache Airflow com 7 DAGs para automa√ß√£o completa
- ‚úÖ **Visualiza√ß√£o Interativa**: Dashboards em Apache Superset e Grafana
- ‚úÖ **Monitoramento 24/7**: Prometheus + Grafana para observabilidade do pipeline
- ‚úÖ **Qualidade de Dados**: Data quality checks automatizados em cada camada

### M√©tricas e KPIs Implementados

| KPI | Descri√ß√£o | Atualiza√ß√£o |
|-----|-----------|-------------|
| **Cobertura de Frota** | % de ve√≠culos operando vs programados | Tempo real |
| **Velocidade M√©dia** | Por rota, corredor e sistema | A cada 15 min |
| **Headway** | Tempo entre √¥nibus consecutivos | Tempo real |
| **Pontualidade** | An√°lise de atrasos/adiantamentos | Hor√°ria |
| **Ocupa√ß√£o de Corredor** | Densidade de ve√≠culos por via | A cada 5 min |
| **Tempo de Viagem** | Dura√ß√£o real vs programada | Por viagem |
| **Congestionamento** | Identifica√ß√£o de gargalos | Tempo real |

---

## üèóÔ∏è Arquitetura

### Vis√£o Macro

```
API SPTrans ‚Üí Spark Batch ‚Üí MinIO (Bronze) ‚Üí Spark ‚Üí Delta Lake (Silver/Gold) ‚Üí PostgreSQL ‚Üí Dashboards
     ‚Üì                                                        ‚Üì
  GTFS Data                                            Redis Cache
     ‚Üì                                                        ‚Üì
Apache Airflow (Orquestra√ß√£o) ‚Üê Prometheus + Grafana (Monitoramento)
```

### Camadas do Pipeline

1. **Data Sources**
   - API SPTrans Olho Vivo (posi√ß√µes em tempo real)
   - GTFS SPTrans (dados est√°ticos: rotas, paradas, hor√°rios)

2. **Ingestion Layer**
   - Apache Spark Batch Jobs (orquestrados por Airflow)
   - Coleta a cada 2 minutos
   - Valida√ß√£o de schema na entrada

3. **Storage Layer (Data Lake)**
   - **MinIO** (S3-compatible object storage)
   - **Bronze**: Raw data em Parquet (particionado por data)
   - **Silver**: Cleaned data com Delta Lake (deduplicado, validado, enriquecido)
   - **Gold**: Aggregated data com Delta Lake (KPIs, m√©tricas agregadas)

4. **Processing Layer**
   - **Apache Spark** para todas as transforma√ß√µes
   - Jobs batch orquestrados por Airflow
   - Data quality checks em cada transforma√ß√£o

5. **Serving Layer**
   - **PostgreSQL**: Data Warehouse com dados agregados para dashboards
   - **Redis**: Cache para dados de tempo real (TTL 2 minutos)

6. **Presentation Layer**
   - **Apache Superset**: Dashboards interativos e an√°lises
   - **Grafana**: Monitoramento do sistema e KPIs operacionais

7. **Orchestration & Monitoring**
   - **Apache Airflow**: Orquestra√ß√£o de todos os jobs
   - **Prometheus + Grafana**: M√©tricas e alertas do pipeline

### Fluxo de Dados Detalhado

Ver documenta√ß√£o completa em: [`docs/01_architecture.md`](docs/01_architecture.md)

---

## üõ†Ô∏è Tecnologias Utilizadas

### Core Stack (100% Open Source)

| Categoria | Tecnologia | Vers√£o | Justificativa |
|-----------|-----------|---------|---------------|
| **Orquestra√ß√£o** | Apache Airflow | 2.8.0 | Padr√£o de mercado, scheduler robusto |
| **Processing** | Apache Spark | 3.5.0 | Processamento distribu√≠do, alta performance |
| **Storage** | MinIO | RELEASE.2024 | S3-compatible, escal√°vel, baixo custo |
| **Table Format** | Delta Lake | 3.0.0 | ACID transactions, time travel |
| **Data Warehouse** | PostgreSQL | 16.0 | Serving layer otimizado para OLAP |
| **Cache** | Redis | 7.2 | Cache de baixa lat√™ncia para real-time |
| **Visualization** | Apache Superset | 3.0 | BI moderno e flex√≠vel |
| **Monitoring** | Prometheus | 2.48 | M√©tricas e alertas |
| **Monitoring** | Grafana | 10.2 | Dashboards de observabilidade |
| **Message Queue** | Apache Kafka | 3.6 | (Opcional) Streaming real-time |

### Linguagens e Frameworks

- **Python 3.11**: Linguagem principal
- **PySpark**: Processamento distribu√≠do
- **SQL**: Queries e transforma√ß√µes
- **Docker**: Containeriza√ß√£o
- **Docker Compose**: Orquestra√ß√£o local

---

## üìÅ Estrutura do Projeto

```
sptrans-realtime-pipeline/
‚îú‚îÄ‚îÄ üìÇ docs/              # Documenta√ß√£o completa
‚îú‚îÄ‚îÄ üìÇ infra/             # Docker, Kubernetes, Terraform
‚îú‚îÄ‚îÄ üìÇ config/            # Configura√ß√µes de servi√ßos
‚îú‚îÄ‚îÄ üìÇ sql/               # Scripts SQL (serving layer)
‚îú‚îÄ‚îÄ üìÇ src/               # C√≥digo-fonte Python
‚îÇ   ‚îú‚îÄ‚îÄ common/           # Utils, config, logging
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/        # Clientes API e schemas
‚îÇ   ‚îú‚îÄ‚îÄ processing/       # Spark jobs e transforma√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ serving/          # Load para PostgreSQL/Redis
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/       # Health checks e alertas
‚îú‚îÄ‚îÄ üìÇ dags/              # DAGs do Airflow
‚îú‚îÄ‚îÄ üìÇ tests/             # Testes unit√°rios e integra√ß√£o
‚îú‚îÄ‚îÄ üìÇ scripts/           # Scripts auxiliares
‚îú‚îÄ‚îÄ üìÇ notebooks/         # Jupyter notebooks (EDA)
‚îî‚îÄ‚îÄ üìÇ dashboards/        # Dashboards exportados
```

Ver estrutura completa: [`docs/02_setup_guide.md`](docs/02_setup_guide.md)

---

## üìã Pr√©-requisitos

### Hardware M√≠nimo

- **CPU**: 4+ cores (8+ recomendado)
- **RAM**: 16GB (32GB recomendado para Spark)
- **Storage**: 100GB SSD
- **Network**: 10Mbps+ (API SPTrans)

### Software

- **Docker** 24.0+
- **Docker Compose** 2.20+
- **Git** 2.40+
- **Python** 3.11+ (para desenvolvimento local)
- **Make** (opcional, para comandos √∫teis)

### Credenciais Necess√°rias

1. **Token API SPTrans**: Solicitar em https://www.sptrans.com.br/desenvolvedores/
2. **SMTP** (opcional): Para envio de alertas por email

---

## üöÄ Instala√ß√£o

### 1. Clone o Reposit√≥rio

```bash
git clone https://github.com/rafarpl/sp-trans-pipeline.git
cd sp-trans-pipeline
```

### 2. Configure Vari√°veis de Ambiente

```bash
cp .env.example .env
nano .env  # Edite com suas credenciais
```

**Vari√°veis obrigat√≥rias:**
```bash
SPTRANS_API_TOKEN=seu_token_aqui
POSTGRES_PASSWORD=senha_segura
```

### 3. Inicie os Servi√ßos

```bash
# Usando Make (recomendado)
make setup

# OU manualmente
docker-compose up -d
```

Isso ir√° iniciar:
- ‚úÖ MinIO (Data Lake)
- ‚úÖ PostgreSQL (Data Warehouse)
- ‚úÖ Redis (Cache)
- ‚úÖ Airflow (Webserver, Scheduler, Workers)
- ‚úÖ Spark (Master + 2 Workers)
- ‚úÖ Superset (Dashboards)
- ‚úÖ Prometheus + Grafana (Monitoring)

### 4. Verifique Status dos Servi√ßos

```bash
make status

# OU
docker-compose ps
```

**URLs de Acesso:**
- **Airflow**: http://localhost:8080 (admin/admin)
- **MinIO Console**: http://localhost:9001 (minioadmin/minioadmin)
- **Superset**: http://localhost:8088 (admin/admin)
- **Grafana**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090

---

## ‚öôÔ∏è Configura√ß√£o

### 1. Inicializar Data Lake (MinIO)

```bash
# Criar buckets necess√°rios
make init-minio

# OU manualmente
docker-compose exec minio mc mb minio/sptrans-bronze
docker-compose exec minio mc mb minio/sptrans-silver
docker-compose exec minio mc mb minio/sptrans-gold
```

### 2. Criar Schemas no PostgreSQL

```bash
# Executar todos os scripts SQL
make init-postgres

# OU manualmente
docker-compose exec postgres psql -U airflow -f /sql/00_create_databases.sql
docker-compose exec postgres psql -U airflow -d sptrans -f /sql/01_serving_schema.sql
```

### 3. Baixar Dados GTFS

```bash
# Download autom√°tico
make download-gtfs

# OU manualmente
python scripts/download_gtfs.py
```

### 4. Ativar DAGs no Airflow

Acesse http://localhost:8080 e ative:

1. ‚úÖ `gtfs_ingestion_daily` - Carga di√°ria GTFS (3h AM)
2. ‚úÖ `api_ingestion_realtime` - Ingest√£o API (a cada 2 min)
3. ‚úÖ `bronze_to_silver` - Limpeza e valida√ß√£o (a cada 10 min)
4. ‚úÖ `silver_to_gold` - Agrega√ß√µes (a cada 15 min)
5. ‚úÖ `gold_to_serving` - Load PostgreSQL (a cada 15 min)
6. ‚úÖ `data_quality_monitoring` - DQ checks (hor√°ria)
7. ‚úÖ `maintenance_cleanup` - Limpeza (di√°ria, 2h AM)

---

## üíª Uso

### Executar Ingest√£o Manual

```bash
# Trigger DAG via CLI
docker-compose exec airflow-scheduler airflow dags trigger api_ingestion_realtime

# OU via UI
# Acesse http://localhost:8080 ‚Üí DAGs ‚Üí Play button
```

### Consultar Dados no Data Lake

```python
# Notebook Jupyter ou Spark Shell
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("SPTrans Analysis") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .getOrCreate()

# Ler camada Bronze
df_bronze = spark.read.parquet("s3a://sptrans-bronze/api_positions/")
df_bronze.show()

# Ler camada Silver (Delta Lake)
df_silver = spark.read.format("delta").load("s3a://sptrans-silver/positions_cleaned/")
df_silver.show()

# Ler camada Gold (agregado)
df_gold = spark.read.format("delta").load("s3a://sptrans-gold/kpis_hourly/")
df_gold.show()
```

### Consultar Dados no PostgreSQL

```sql
-- Conectar ao PostgreSQL
docker-compose exec postgres psql -U airflow -d sptrans

-- Ver KPIs em tempo real
SELECT * FROM serving.kpis_realtime ORDER BY updated_at DESC LIMIT 10;

-- Velocidade m√©dia por rota
SELECT 
    route_short_name,
    AVG(speed_kmh) as avg_speed,
    COUNT(*) as samples
FROM serving.route_metrics
WHERE timestamp >= NOW() - INTERVAL '1 hour'
GROUP BY route_short_name
ORDER BY avg_speed DESC;
```

### Acessar Cache Redis

```bash
# Conectar ao Redis
docker-compose exec redis redis-cli

# Ver posi√ß√µes em cache
KEYS bus:position:*
GET bus:position:12345

# Ver estat√≠sticas
INFO stats
```

---

## üìä Dashboards e KPIs

### Apache Superset

Acesse: http://localhost:8088

**Dashboards Dispon√≠veis:**

1. **Operational Dashboard**
   - Total de ve√≠culos ativos
   - Mapa de posi√ß√µes em tempo real
   - Velocidade m√©dia por corredor
   - Alertas ativos

2. **Executive Summary**
   - KPIs principais (cards)
   - Tend√™ncias semanais
   - Comparativos dia √∫til vs fim de semana

3. **Route Performance**
   - Ranking de rotas por pontualidade
   - Headway m√©dio por linha
   - An√°lise de desvios

### Grafana (Monitoring)

Acesse: http://localhost:3000

**Dashboards:**

1. **Pipeline Monitoring**
   - Taxa de sucesso dos DAGs
   - Lat√™ncia de ingest√£o
   - Throughput de processamento
   - Erros e retries

2. **Data Quality**
   - % de registros v√°lidos
   - Duplicatas detectadas
   - Outliers identificados
   - Completude dos dados

---

## üß™ Testes

### Executar Todos os Testes

```bash
# Usando Make
make test

# OU manualmente
docker-compose exec airflow-worker pytest tests/ -v
```

### Testes Unit√°rios

```bash
pytest tests/unit/ -v
```

### Testes de Integra√ß√£o

```bash
pytest tests/integration/ -v
```

### Cobertura de Testes

```bash
make test-coverage

# Gera relat√≥rio HTML em htmlcov/index.html
```

---

## üìà Monitoramento

### Health Checks

```bash
# Via script
make health-check

# OU manualmente
curl http://localhost:8080/health  # Airflow
curl http://localhost:9000/minio/health/live  # MinIO
```

### Logs

```bash
# Airflow logs
docker-compose logs -f airflow-scheduler

# Spark logs
docker-compose logs -f spark-master

# Todos os servi√ßos
docker-compose logs -f
```

### M√©tricas Prometheus

Acesse: http://localhost:9090

**Queries √∫teis:**
```promql
# Taxa de sucesso de ingest√£o
rate(airflow_dag_run_success_total{dag_id="api_ingestion_realtime"}[5m])

# Lat√™ncia de processamento
histogram_quantile(0.95, rate(spark_job_duration_seconds_bucket[5m]))

# Erros no pipeline
sum(rate(pipeline_errors_total[5m])) by (component)
```

---

## üîß Troubleshooting

### Problemas Comuns

| Problema | Solu√ß√£o |
|----------|---------|
| **DAG n√£o aparece no Airflow** | Verificar logs: `docker-compose logs airflow-scheduler` |
| **Erro de conex√£o MinIO** | Verificar credenciais no `.env` e restart: `make restart-minio` |
| **Spark job travado** | Verificar recursos: `docker stats` e aumentar mem√≥ria se necess√°rio |
| **API SPTrans timeout** | Verificar token v√°lido e conectividade: `curl -H "Authorization: Bearer $TOKEN" https://api.olhovivo.sptrans.com.br/v2.1/Posicao` |

Ver guia completo: [`docs/05_troubleshooting.md`](docs/05_troubleshooting.md)

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Para contribuir:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

### Guidelines

- Siga PEP 8 para c√≥digo Python
- Adicione testes para novas funcionalidades
- Atualize documenta√ß√£o quando necess√°rio
- Use commits sem√¢nticos (feat, fix, docs, etc)

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja [LICENSE](LICENSE) para mais detalhes.

---

## üë• Autores

**Rafael** - Projeto de Conclus√£o FIA/LABDATA  
GitHub: [@rafarpl](https://github.com/rafarpl)

---

## üôè Agradecimentos

- **SPTrans** pela disponibiliza√ß√£o da API Olho Vivo
- **FIA/LABDATA** pelo programa de Engenharia de Dados
- Comunidades **Apache Airflow**, **Spark**, **Delta Lake**
- Todos os contribuidores do ecossistema open source

---

## üìö Documenta√ß√£o Adicional

- [Arquitetura Detalhada](docs/01_architecture.md)
- [Guia de Setup](docs/02_setup_guide.md)
- [Dicion√°rio de Dados](docs/03_data_dictionary.md)
- [Refer√™ncia API SPTrans](docs/04_api_reference.md)
- [Troubleshooting](docs/05_troubleshooting.md)
- [Justificativas T√©cnicas](docs/06_justifications.md)
- [Cat√°logo de Metadados](docs/07_metadata_catalog.md)

---

**üöÄ Desenvolvido com ‚ù§Ô∏è para melhorar o transporte p√∫blico de S√£o Paulo**
