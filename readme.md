# ğŸšŒ SPTrans Data Pipeline

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-2.8-red.svg)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.5-orange.svg)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

**Pipeline de dados em tempo real para anÃ¡lise do sistema de transporte pÃºblico de SÃ£o Paulo**

[DocumentaÃ§Ã£o](docs/) Â· [Arquitetura](docs/01_architecture.md) Â· [API Reference](docs/04_api_reference.md) Â· [Troubleshooting](docs/05_troubleshooting.md)

</div>

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Features](#-features)
- [Tecnologias](#-tecnologias)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Uso](#-uso)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [DAGs do Airflow](#-dags-do-airflow)
- [Monitoramento](#-monitoramento)
- [Testes](#-testes)
- [Contribuindo](#-contribuindo)
- [LicenÃ§a](#-licenÃ§a)

---

## ğŸ¯ VisÃ£o Geral

O **SPTrans Data Pipeline** Ã© uma soluÃ§Ã£o completa de engenharia de dados para coletar, processar e analisar dados em tempo real do sistema de transporte pÃºblico de SÃ£o Paulo. O pipeline integra dados da API Olho Vivo da SPTrans e arquivos GTFS para fornecer insights operacionais e estratÃ©gicos.

### ğŸ Principais CaracterÃ­sticas

- âš¡ **IngestÃ£o em tempo real** - Coleta de posiÃ§Ãµes dos Ã´nibus a cada 2 minutos
- ğŸ—ï¸ **Arquitetura Lakehouse** - Camadas Bronze, Silver e Gold para processamento estruturado
- ğŸ“Š **Dashboards interativos** - VisualizaÃ§Ãµes com Superset e Grafana
- ğŸ” **Monitoramento completo** - MÃ©tricas, alertas e observabilidade
- ğŸ§ª **Qualidade de dados** - ValidaÃ§Ã£o, limpeza e enriquecimento automatizados
- ğŸ“ˆ **KPIs operacionais** - AnÃ¡lise de performance, headway e acessibilidade

---

## ğŸ›ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API SPTrans    â”‚
â”‚  GTFS Files     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INGESTION LAYER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ API Client  â”‚          â”‚ GTFS        â”‚          â”‚
â”‚  â”‚ (Python)    â”‚          â”‚ Downloader  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                        â”‚
          â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DATA LAKE (MinIO - S3 Compatible)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  BRONZE LAYER (Raw Data)                     â”‚  â”‚
â”‚  â”‚  - api_positions/                            â”‚  â”‚
â”‚  â”‚  - gtfs/routes, stops, trips, shapes         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                   â”‚
â”‚                 â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  SILVER LAYER (Cleaned & Enriched)          â”‚  â”‚
â”‚  â”‚  - positions_enriched                        â”‚  â”‚
â”‚  â”‚  - Validated, deduplicated, geocoded        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                   â”‚
â”‚                 â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  GOLD LAYER (Aggregated & Analytics)        â”‚  â”‚
â”‚  â”‚  - kpis_hourly                               â”‚  â”‚
â”‚  â”‚  - metrics_by_route                          â”‚  â”‚
â”‚  â”‚  - headway_analysis                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           SERVING LAYER (PostgreSQL)                â”‚
â”‚  - Materialized Views                               â”‚
â”‚  - Optimized Indexes                                â”‚
â”‚  - Real-time Queries                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        VISUALIZATION & ANALYTICS                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Superset   â”‚  â”‚   Grafana   â”‚  â”‚  Jupyter   â”‚  â”‚
â”‚  â”‚  (BI)       â”‚  â”‚  (Metrics)  â”‚  â”‚  (Analysis)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Orchestration: Apache Airflow
Processing: Apache Spark
Monitoring: Prometheus + Grafana
```

---

## âœ¨ Features

### ğŸ“¥ IngestÃ£o de Dados

- **API em Tempo Real**: Coleta de posiÃ§Ãµes dos Ã´nibus a cada 2 minutos
- **Dados EstÃ¡ticos GTFS**: Download diÃ¡rio de rotas, paradas e horÃ¡rios
- **Resiliente**: Retry automÃ¡tico, tratamento de erros, circuit breaker

### ğŸ”„ Processamento

- **ValidaÃ§Ã£o**: Coordenadas, timestamps, IDs de veÃ­culos
- **Limpeza**: DeduplicaÃ§Ã£o, normalizaÃ§Ã£o, tratamento de nulos
- **Enriquecimento**: Join com dados GTFS, geocoding reverso
- **AgregaÃ§Ãµes**: KPIs por hora/dia/rota, anÃ¡lise de headway

### ğŸ“Š Analytics

- **KPIs Operacionais**:
  - Total de veÃ­culos ativos
  - Velocidade mÃ©dia e mÃ¡xima
  - Taxa de movimentaÃ§Ã£o
  - Acessibilidade

- **AnÃ¡lise de Performance**:
  - Headway (intervalo entre Ã´nibus)
  - Regularidade do serviÃ§o
  - DistÃ¢ncia percorrida
  - Horas de operaÃ§Ã£o

- **Qualidade de Dados**:
  - Score de completude
  - Taxa de validade
  - Alertas automÃ¡ticos

### ğŸ¯ VisualizaÃ§Ã£o

- **Dashboards Executivos** (Superset): VisÃ£o geral do sistema
- **Monitoramento TÃ©cnico** (Grafana): MÃ©tricas de infraestrutura
- **AnÃ¡lises Ad-hoc** (Jupyter): Notebooks interativos

---

## ğŸ› ï¸ Tecnologias

### Core Stack

| Tecnologia | VersÃ£o | FunÃ§Ã£o |
|-----------|--------|--------|
| **Python** | 3.10+ | Linguagem principal |
| **Apache Airflow** | 2.8.1 | OrquestraÃ§Ã£o de pipelines |
| **Apache Spark** | 3.5.0 | Processamento distribuÃ­do |
| **PostgreSQL** | 15 | Database (Airflow + Serving) |
| **MinIO** | Latest | Data Lake (S3-compatible) |
| **Redis** | 7 | Cache e message broker |

### Monitoramento

| Tecnologia | FunÃ§Ã£o |
|-----------|--------|
| **Prometheus** | Coleta de mÃ©tricas |
| **Grafana** | Dashboards de monitoramento |
| **Apache Superset** | BI e dashboards analÃ­ticos |

### Bibliotecas Python

```
pandas, numpy, pyspark, psycopg2-binary, 
boto3, requests, prometheus-client, pytest
```

Veja [requirements.txt](requirements.txt) para lista completa.

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM mÃ­nimo (16GB recomendado)
- 20GB espaÃ§o em disco

### Quick Start

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/rafarpl/sptrans-pipeline.git
cd sptrans-pipeline

# 2. Configure variÃ¡veis de ambiente
cp .env.example .env
# Edite .env e adicione seu token da API SPTrans

# 3. Execute setup inicial
chmod +x scripts/*.sh
./scripts/setup.sh

# 4. Inicie os serviÃ§os
make start
# ou: ./scripts/start_services.sh
```

### ConfiguraÃ§Ã£o do Token da API

1. Obtenha seu token em: https://www.sptrans.com.br/desenvolvedores/
2. Adicione no arquivo `.env`:
   ```
   SPTRANS_API_TOKEN=seu_token_aqui
   ```

### VerificaÃ§Ã£o

Aguarde ~2 minutos para todos os serviÃ§os iniciarem, entÃ£o acesse:

- **Airflow**: http://localhost:8080 (admin/admin)
- **Spark UI**: http://localhost:8081
- **MinIO Console**: http://localhost:9001 (admin/miniopassword123)
- **Grafana**: http://localhost:3000 (admin/admin)
- **Superset**: http://localhost:8088 (admin/admin)

---

## ğŸ“– Uso

### Comandos Make

```bash
# Gerenciamento de ServiÃ§os
make start          # Inicia todos os serviÃ§os
make stop           # Para todos os serviÃ§os
make restart        # Reinicia serviÃ§os
make ps             # Status dos containers
make logs           # Logs de todos os serviÃ§os

# Acesso RÃ¡pido (abre no navegador)
make airflow        # Abre Airflow UI
make spark          # Abre Spark UI
make minio          # Abre MinIO Console
make grafana        # Abre Grafana
make superset       # Abre Superset

# Database
make db-shell       # Acessa PostgreSQL
make db-create-tables  # Cria tabelas
make db-backup      # Backup do banco

# Data Lake
make minio-list-bronze  # Lista arquivos Bronze
make minio-list-silver  # Lista arquivos Silver
make minio-list-gold    # Lista arquivos Gold

# Testes
make test           # Executa todos os testes
make test-unit      # Testes unitÃ¡rios
make test-integration  # Testes de integraÃ§Ã£o
make lint           # Linter (flake8)

# Desenvolvimento
make notebook       # Inicia Jupyter Lab
make shell          # Shell do container

# InformaÃ§Ãµes
make help           # Lista todos os comandos
make status         # Status completo do sistema
make info           # InformaÃ§Ãµes do projeto
```

### Executando DAGs

1. Acesse o Airflow: http://localhost:8080
2. Ative as DAGs desejadas:
   - `dag_01_gtfs_ingestion` - IngestÃ£o diÃ¡ria GTFS
   - `dag_02_api_ingestion` - IngestÃ£o API (2 min)
   - `dag_03_bronze_to_silver` - TransformaÃ§Ã£o Silver
   - `dag_04_silver_to_gold` - AgregaÃ§Ã£o Gold
   - `dag_05_gold_to_serving` - Load PostgreSQL

---

## ğŸ“ Estrutura do Projeto

```
sptrans-pipeline/
â”œâ”€â”€ config/                 # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ airflow/           # Airflow configs
â”‚   â”œâ”€â”€ spark/             # Spark configs
â”‚   â”œâ”€â”€ prometheus/        # Prometheus configs
â”‚   â””â”€â”€ grafana/           # Grafana datasources
â”‚
â”œâ”€â”€ dags/                   # Airflow DAGs
â”‚   â”œâ”€â”€ dag_01_gtfs_ingestion.py
â”‚   â”œâ”€â”€ dag_02_api_ingestion.py
â”‚   â”œâ”€â”€ dag_03_bronze_to_silver.py
â”‚   â”œâ”€â”€ dag_04_silver_to_gold.py
â”‚   â””â”€â”€ dag_05_gold_to_serving.py
â”‚
â”œâ”€â”€ docs/                   # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ 01_architecture.md
â”‚   â”œâ”€â”€ 02_setup_guide.md
â”‚   â”œâ”€â”€ 03_data_dictionary.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ infra/                  # Infraestrutura
â”‚   â”œâ”€â”€ docker/            # Dockerfiles
â”‚   â””â”€â”€ kubernetes/        # K8s manifests
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”‚   â””â”€â”€ 01_exploratory_data_analysis.ipynb
â”‚
â”œâ”€â”€ scripts/                # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ setup.sh
â”‚   â”œâ”€â”€ start_services.sh
â”‚   â””â”€â”€ backup_data.sh
â”‚
â”œâ”€â”€ sql/                    # Scripts SQL
â”‚   â”œâ”€â”€ 01_serving_schema.sql
â”‚   â”œâ”€â”€ 02_serving_tables.sql
â”‚   â”œâ”€â”€ 03_materialized_views.sql
â”‚   â””â”€â”€ 04_indexes.sql
â”‚
â”œâ”€â”€ src/                    # CÃ³digo fonte
â”‚   â”œâ”€â”€ common/            # CÃ³digo compartilhado
â”‚   â”œâ”€â”€ ingestion/         # Camada de ingestÃ£o
â”‚   â”œâ”€â”€ processing/        # Processamento Spark
â”‚   â”œâ”€â”€ serving/           # Camada de serving
â”‚   â””â”€â”€ monitoring/        # Monitoramento
â”‚
â”œâ”€â”€ tests/                  # Testes
â”‚   â”œâ”€â”€ unit/              # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ integration/       # Testes de integraÃ§Ã£o
â”‚   â””â”€â”€ fixtures/          # Dados de teste
â”‚
â”œâ”€â”€ .env.example           # Template de variÃ¡veis
â”œâ”€â”€ .gitignore             # Git ignore
â”œâ”€â”€ docker-compose.yml     # OrquestraÃ§Ã£o Docker
â”œâ”€â”€ Makefile              # Comandos Ãºteis
â”œâ”€â”€ README.md             # Este arquivo
â””â”€â”€ requirements.txt      # DependÃªncias Python
```

---

## ğŸ”„ DAGs do Airflow

### DAG 01 - GTFS Ingestion
- **FrequÃªncia**: DiÃ¡ria (2 AM)
- **FunÃ§Ã£o**: Download e ingestÃ£o de dados GTFS estÃ¡ticos
- **Output**: Bronze Layer (routes, stops, trips, shapes)

### DAG 02 - API Ingestion
- **FrequÃªncia**: A cada 2 minutos
- **FunÃ§Ã£o**: Coleta de posiÃ§Ãµes em tempo real
- **Output**: Bronze Layer (api_positions)

### DAG 03 - Bronze to Silver
- **FrequÃªncia**: A cada 30 minutos
- **FunÃ§Ã£o**: Limpeza, validaÃ§Ã£o e enriquecimento
- **Output**: Silver Layer (positions_enriched)

### DAG 04 - Silver to Gold
- **FrequÃªncia**: A cada hora
- **FunÃ§Ã£o**: AgregaÃ§Ãµes e cÃ¡lculo de KPIs
- **Output**: Gold Layer (kpis_hourly, metrics_by_route, headway_analysis)

### DAG 05 - Gold to Serving
- **FrequÃªncia**: A cada hora (15 min apÃ³s DAG 04)
- **FunÃ§Ã£o**: Load para PostgreSQL
- **Output**: Serving Layer (PostgreSQL tables)

---

## ğŸ“Š Monitoramento

### MÃ©tricas DisponÃ­veis

- **Pipeline**: Taxa de sucesso, tempo de execuÃ§Ã£o, registros processados
- **Data Quality**: Completude, acurÃ¡cia, validade
- **Infraestrutura**: CPU, memÃ³ria, disco, rede
- **AplicaÃ§Ã£o**: LatÃªncia API, throughput Spark, queries PostgreSQL

### Dashboards

**Grafana** (http://localhost:3000):
- System Monitoring
- Data Quality
- Pipeline Performance

**Superset** (http://localhost:8088):
- Operational Dashboard
- Executive Summary
- Route Analysis

---

## ğŸ§ª Testes

```bash
# Todos os testes
make test

# Testes unitÃ¡rios
make test-unit

# Testes de integraÃ§Ã£o
make test-integration

# Com cobertura
make test-coverage

# Lint
make lint
```

### Cobertura de Testes

- Validadores: 95%+
- API Client: 90%+
- TransformaÃ§Ãµes: 85%+
- Jobs Spark: 80%+

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [Arquitetura Detalhada](docs/01_architecture.md)
- [Guia de InstalaÃ§Ã£o](docs/02_setup_guide.md)
- [DicionÃ¡rio de Dados](docs/03_data_dictionary.md)
- [ReferÃªncia da API](docs/04_api_reference.md)
- [Troubleshooting](docs/05_troubleshooting.md)
- [Justificativas TÃ©cnicas](docs/06_justifications.md)
- [CatÃ¡logo de Metadados](docs/07_metadata_catalog.md)

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

### Guidelines

- Siga o style guide PEP 8
- Adicione testes para novas features
- Atualize a documentaÃ§Ã£o
- Mantenha cobertura de testes > 80%

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ‘¥ Autores

- **Rafael** - *Engenheiro de Dados* - [GitHub](https://github.com/rafarpl)

---

## ğŸ™ Agradecimentos

- **SPTrans** - Por disponibilizar a API Olho Vivo
- **Comunidade Open Source** - Pelas ferramentas incrÃ­veis

---

## ğŸ“ Suporte

- ğŸ“§ Email: rafael@example.com
- ğŸ› Issues: [GitHub Issues](https://github.com/rafarpl/sptrans-pipeline/issues)
- ğŸ“– Docs: [DocumentaÃ§Ã£o Completa](docs/)

---

<div align="center">

**â­ Se este projeto foi Ãºtil, considere dar uma estrela!**

Made with â¤ï¸ and â˜• by Rafael

</div>
