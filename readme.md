# ğŸš SPTrans Real-Time Data Pipeline

Pipeline de dados em tempo real para monitoramento e anÃ¡lise do sistema de transporte pÃºblico de SÃ£o Paulo, processando dados GPS de aproximadamente 15.000 Ã´nibus da SPTrans.

![Dashboard Grafana](docs/dashboard-screenshot.png)

---

## ğŸ“Š VisÃ£o Geral do Projeto

Sistema completo de engenharia de dados que coleta, processa e visualiza dados em tempo real da API Olho Vivo da SPTrans, implementando uma arquitetura Medallion (Bronze â†’ Silver â†’ Gold) com processamento distribuÃ­do.

DocumentaÃ§Ã£o e apresentaÃ§Ã£o na pasta /docs

### ğŸ¯ Objetivos

- Monitoramento em tempo real da frota de Ã´nibus de SÃ£o Paulo
- AnÃ¡lise de performance por linha (velocidade mÃ©dia, cobertura, pontualidade)
- VisualizaÃ§Ã£o geogrÃ¡fica da localizaÃ§Ã£o dos veÃ­culos
- MÃ©tricas de qualidade de dados e saÃºde do pipeline
- Dashboard interativo com atualizaÃ§Ã£o automÃ¡tica a cada 30 segundos

---

## ğŸ—ï¸ Arquitetura do Sistema
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     API SPTrans Olho Vivo                       â”‚
â”‚              ~15.000 Ã´nibus | ~1.000 linhas ativas              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP REST API
                         â”‚ AutenticaÃ§Ã£o via Token
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CAMADA BRONZE (Raw Data)                      â”‚
â”‚                     Apache Spark (PySpark)                      â”‚
â”‚                 â€¢ IngestÃ£o via API Client                       â”‚
â”‚                 â€¢ ~10.8M registros/dia                           â”‚
â”‚                 â€¢ ValidaÃ§Ã£o bÃ¡sica de schema                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CAMADA SILVER (Validated)                      â”‚
â”‚                     Apache Spark (PySpark)                      â”‚
â”‚                 â€¢ ValidaÃ§Ã£o de coordenadas                      â”‚
â”‚                 â€¢ CÃ¡lculo de velocidade (Haversine)             â”‚
â”‚                 â€¢ DeduplicaÃ§Ã£o                                  â”‚
â”‚                 â€¢ Limpeza de dados                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CAMADA GOLD (Aggregated)                      â”‚
â”‚                     Apache Spark (PySpark)                      â”‚
â”‚                 â€¢ AgregaÃ§Ãµes por linha                          â”‚
â”‚                 â€¢ CÃ¡lculo de KPIs                               â”‚
â”‚                 â€¢ MÃ©tricas de qualidade                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CAMADA SERVING (Analytics)                    â”‚
â”‚                        PostgreSQL 15                            â”‚
â”‚                 â€¢ kpi_realtime (mÃ©tricas globais)               â”‚
â”‚                 â€¢ kpi_by_line (anÃ¡lise por linha)               â”‚
â”‚                 â€¢ kpi_quality (qualidade do pipeline)           â”‚
â”‚                 â€¢ vehicle_positions_latest (mapa)               â”‚
â”‚                 â€¢ kpi_timeseries (sÃ©ries temporais)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VISUALIZAÃ‡ÃƒO (Dashboard)                     â”‚
â”‚                         Grafana 10+                             â”‚
â”‚                 â€¢ 6 painÃ©is interativos                         â”‚
â”‚                 â€¢ Mapa geogrÃ¡fico (OpenStreetMap)               â”‚
â”‚                 â€¢ Auto-refresh 30s                              â”‚
â”‚                 â€¢ Tema escuro                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Tecnologias Utilizadas

### **Processamento de Dados**
- **Apache Spark 3.5** - Processamento distribuÃ­do
- **PySpark** - Interface Python para Spark
- **Delta Lake** - Armazenamento ACID

### **Armazenamento**
- **PostgreSQL 15** - Banco de dados relacional (camada serving)
- **MinIO** - Object storage S3-compatible (data lake)
- **Redis** - Cache e fila de mensagens

### **OrquestraÃ§Ã£o & DevOps**
- **Docker Compose** - ContainerizaÃ§Ã£o
- **GitHub Actions** - CI/CD (planejado)

### **VisualizaÃ§Ã£o**
- **Grafana** - Dashboards interativos
- **OpenStreetMap** - Mapas geogrÃ¡ficos

### **Linguagens & Frameworks**
- **Python 3.12**
- **Pydantic** - ValidaÃ§Ã£o de configuraÃ§Ãµes
- **Requests** - Cliente HTTP

---

## ğŸ“Š KPIs e MÃ©tricas Implementadas

### **Operacionais (Tempo Real)**
- ğŸšŒ **VeÃ­culos Ativos**: Quantidade total de Ã´nibus transmitindo posiÃ§Ã£o
- ğŸ“ **Linhas Ativas**: NÃºmero de linhas com veÃ­culos operando
- ğŸ“¡ **Cobertura**: Percentual de linhas cobertas vs total da rede (~400 linhas)
- â±ï¸ **Staleness**: Percentual de veÃ­culos com dados desatualizados (>4 min)

### **Por Linha**
- ğŸšŒ **Frota Ativa**: Quantidade de veÃ­culos por linha
- ğŸƒ **Velocidade MÃ©dia**: Calculada via fÃ³rmula de Haversine entre capturas
- ğŸ“ˆ **Velocidade MÃ¡xima/MÃ­nima**: Extremos de velocidade
- ğŸ“Š **DistribuiÃ§Ã£o de Velocidade**: Faixas 0-20, 20-40, 40-60, 60+ km/h

### **Qualidade de Dados**
- âœ… **Taxa de ValidaÃ§Ã£o**: % de registros que passam nas validaÃ§Ãµes
- ğŸ“¦ **Registros Processados**: Volume de dados por iteraÃ§Ã£o
- â±ï¸ **Tempo de ExecuÃ§Ã£o**: DuraÃ§Ã£o do processamento
- ğŸ”„ **Status do Pipeline**: SaÃºde operacional

---

## ğŸ—ºï¸ Funcionalidades do Dashboard

### **Painel 1: VisÃ£o Operacional**
- MÃ©tricas principais (cards com indicadores visuais)
- SÃ©rie temporal de veÃ­culos ativos (Ãºltimas 2 horas)
- GrÃ¡fico de linhas com maior frota

### **Painel 2: AnÃ¡lise por Linha**
- Top 10 linhas mais ativas (grÃ¡fico de barras)
- Tabela detalhada com velocidade mÃ©dia por linha
- Filtros interativos por linha e perÃ­odo

### **Painel 3: Mapa GeogrÃ¡fico**
- LocalizaÃ§Ã£o em tempo real de todos os veÃ­culos ativos
- Pontos coloridos por linha
- Zoom e navegaÃ§Ã£o interativa
- Tooltip com informaÃ§Ãµes detalhadas (veÃ­culo, linha, velocidade)

### **Painel 4: Qualidade de Dados**
- Status do pipeline (running/stopped)
- Taxa de validaÃ§Ã£o de dados
- MÃ©tricas de staleness
- Tempo de execuÃ§Ã£o

---

## ğŸ“ Estrutura do Projeto
```
sp-trans-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â”œâ”€â”€ config.py              # ConfiguraÃ§Ãµes (Pydantic)
â”‚   â”‚   â”œâ”€â”€ exceptions.py          # ExceÃ§Ãµes customizadas
â”‚   â”‚   â””â”€â”€ logger.py              # Sistema de logs
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ sptrans_api_client.py  # Cliente API SPTrans
â”‚   â””â”€â”€ pipelines/
â”‚       â””â”€â”€ kpi_pipeline.py        # Pipeline principal
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ 08_kpi_tables.sql          # Schema do PostgreSQL
â”œâ”€â”€ docker-compose.yml              # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ pipeline_kpis_completo.py       # Script principal
â”œâ”€â”€ requirements.txt                # DependÃªncias Python
â”œâ”€â”€ .env.example                    # VariÃ¡veis de ambiente
â””â”€â”€ README.md                       # Este arquivo
```

---

## âš™ï¸ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

### **PrÃ©-requisitos**
- Docker & Docker Compose
- Python 3.12+
- Token de API da SPTrans ([solicitar aqui](https://www.sptrans.com.br/desenvolvedores/))
- 8GB RAM mÃ­nimo
- 20GB espaÃ§o em disco

### **1. Clone o RepositÃ³rio**
```bash
git clone https://github.com/rafarpl/sp-trans-pipeline.git
cd sp-trans-pipeline
```

### **2. Configure as VariÃ¡veis de Ambiente**
```bash
cp .env.example .env
nano .env
```

Adicione seu token da API:
```env
SPTRANS_API_TOKEN=seu_token_aqui
SPTRANS_API_BASE_URL=http://api.olhovivo.sptrans.com.br/v2.1
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=sptrans_test
POSTGRES_USER=test_user
POSTGRES_PASSWORD=test_password
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
```

### **3. Suba os Containers**
```bash
docker-compose up -d
```

Aguarde ~30 segundos para todos os serviÃ§os iniciarem.

### **4. Crie o Ambiente Virtual Python**
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
.\venv\Scripts\activate   # Windows
```

### **5. Instale as DependÃªncias**
```bash
pip install -r requirements.txt
```

### **6. Baixe o Driver JDBC PostgreSQL**
```bash
sudo mkdir -p /usr/local/lib
sudo wget -O /usr/local/lib/postgresql-42.7.1.jar https://jdbc.postgresql.org/download/postgresql-42.7.1.jar
```

### **7. Crie as Tabelas no PostgreSQL**
```bash
cat sql/08_kpi_tables.sql | docker exec -i sptrans-postgres psql -U test_user -d sptrans_test
```

### **8. Execute o Pipeline**
```bash
python3 pipeline_kpis_completo.py
```

O pipeline executarÃ¡ a cada 2 minutos automaticamente.

---

## ğŸ“Š Acessar o Dashboard Grafana

1. **Abrir navegador:** http://localhost:3000
2. **Login:** 
   - Username: `admin`
   - Password: `admin`
   - Clicar "Skip" para nÃ£o trocar senha
3. **Configurar Data Source:**
   - Menu â†’ Configuration â†’ Data sources
   - Add data source â†’ PostgreSQL
   - Preencher:
     - Host: `postgres:5432`
     - Database: `sptrans_test`
     - User: `test_user`
     - Password: `test_password`
     - TLS/SSL Mode: `disable`
   - Save & Test
4. **Dashboard estÃ¡ pronto para uso!**

---

## ğŸ”¢ FÃ³rmulas e Algoritmos

### **CÃ¡lculo de Velocidade (Haversine)**
```python
def calculate_speed(lat1, lon1, lat2, lon2, time_diff_seconds):
    R = 6371.0  # Raio da Terra em km
    
    # Converter para radianos
    lat1_rad = radians(lat1)
    lon1_rad = radians(lon1)
    lat2_rad = radians(lat2)
    lon2_rad = radians(lon2)
    
    # DiferenÃ§as
    dlat = lat2_rad - lat1_rad
    dlon = lon2_rad - lon1_rad
    
    # FÃ³rmula de Haversine
    a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))
    
    distance_km = R * c
    speed_kmh = (distance_km / time_diff_seconds) * 3600
    
    return round(speed_kmh, 2)
```

### **ValidaÃ§Ãµes Implementadas**

- âœ… Coordenadas dentro de SÃ£o Paulo (lat: -24.0 a -23.0, lon: -47.0 a -46.0)
- âœ… Velocidade entre 0-100 km/h
- âœ… Intervalo entre capturas < 10 minutos
- âœ… DeduplicaÃ§Ã£o por (vehicle_id, timestamp)

---

## ğŸ“ˆ Desempenho e Escalabilidade

### **MÃ©tricas Atuais**
- **Volume de Dados**: ~7.200.000 registros/dia
- **FrequÃªncia de AtualizaÃ§Ã£o**: 3 minutos
- **LatÃªncia de Processamento**: 12-18 segundos
- **Taxa de ValidaÃ§Ã£o**: ~99.5%
- **VeÃ­culos Monitorados**: 6.000-8.000 (variÃ¡vel por horÃ¡rio)
- **Linhas Cobertas**: 1.000+ linhas ativas

### **Capacidade**
- Suporta atÃ© 15.000 veÃ­culos simultÃ¢neos
- Processamento distribuÃ­do (Spark com 2 cores)
- Armazenamento escalÃ¡vel (MinIO S3-compatible)

---

## ğŸ§ª Testes
```bash
# Testar conexÃ£o com API
python3 -c "from src.ingestion.sptrans_api_client import SPTransAPIClient; \
            c = SPTransAPIClient(); \
            print('âœ… OK' if c.authenticate() else 'âŒ ERRO')"

# Testar conexÃ£o PostgreSQL
docker exec -it sptrans-postgres psql -U test_user -d sptrans_test -c "SELECT version();"

# Verificar dados
docker exec -it sptrans-postgres psql -U test_user -d sptrans_test -c \
  "SELECT COUNT(*) FROM serving.kpi_realtime;"
```

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [API SPTrans Olho Vivo](https://www.sptrans.com.br/desenvolvedores/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Grafana Documentation](https://grafana.com/docs/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)

---

## ğŸ‘¨â€ğŸ’» Autor

**Rafael Pisciottano LeitÃ£o**
- ğŸ“ PÃ³s-graduaÃ§Ã£o em Data Engineering - FIA/LABDATA (2025)
- ğŸ“§ Email: [rafarpL@gmail.com]
- ğŸ™ GitHub: [@rafarpl](https://github.com/rafarpl)

---

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido como Trabalho de ConclusÃ£o de Curso (TCC) do programa de pÃ³s-graduaÃ§Ã£o em Engenharia de Dados da FIA/LABDATA.

---

## ğŸ™ Agradecimentos

- **SPTrans** - Pela disponibilizaÃ§Ã£o da API Olho Vivo
- **FIA/LABDATA** - Pelo programa de pÃ³s-graduaÃ§Ã£o
- **Comunidade Open Source** - Pelas ferramentas incrÃ­veis

---

â­ **Se este projeto foi Ãºtil, considere dar uma estrela no GitHub!**