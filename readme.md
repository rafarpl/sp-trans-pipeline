# ğŸšŒ SPTrans Real-Time Pipeline

Pipeline de dados em tempo real para anÃ¡lise do sistema de transporte pÃºblico de SÃ£o Paulo.

**Projeto de ConclusÃ£o de Curso** - Engenharia de Dados | FIA/LABDATA

---

## ğŸ“Š VisÃ£o Geral

Pipeline completo de dados que processa **15.000 veÃ­culos** a cada **3 minutos**, gerando:
- ğŸ“ˆ **7,2 milhÃµes de registros/dia**
- ğŸ—ºï¸ Posicionamento em tempo real
- ğŸ“Š KPIs e mÃ©tricas de negÃ³cio
- ğŸ¯ Dashboards interativos

---

## ğŸ—ï¸ Arquitetura

### Medallion Architecture (Bronze â†’ Silver â†’ Gold)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API GTFS   â”‚ â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                  â”œâ”€â”€â–º â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚ BRONZE  â”‚ â”€â”€â–ºâ”‚ SILVER  â”‚ â”€â”€â–ºâ”‚ GOLD â”‚ â”€â”€â–ºâ”‚ PostgreSQL â”‚
â”‚ API Olho    â”‚ â”€â”€â”˜    â”‚ (MinIO) â”‚    â”‚ (Delta) â”‚    â”‚(Deltaâ”‚    â”‚  (Serving) â”‚
â”‚ Vivo (3min) â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚              â”‚            â”‚               â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           Airflow
```

### Stack TecnolÃ³gico

- **Storage**: MinIO (S3-compatible) + Delta Lake
- **Processing**: Apache Spark (1 Master + 2 Workers)
- **Orchestration**: Apache Airflow (7 DAGs)
- **Database**: PostgreSQL 15 + PostGIS
- **Monitoring**: Prometheus + Grafana
- **BI**: Apache Superset
- **Infra**: Docker Compose

---

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Docker & Docker Compose
- Python 3.9+
- 8GB RAM mÃ­nimo
- 50GB disco disponÃ­vel

### InstalaÃ§Ã£o

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/rafarpl/sp-trans-pipeline.git
cd sp-trans-pipeline

# 2. Configure variÃ¡veis de ambiente
cp config/.env.example config/.env
# Edite .env com suas credenciais da API SPTrans

# 3. Inicialize a infraestrutura
make setup
make up

# 4. Crie o database
make db-init

# 5. Execute o pipeline
make airflow-trigger-all
```

### Acesso aos ServiÃ§os

| ServiÃ§o | URL | Credenciais |
|---------|-----|-------------|
| **Airflow** | http://localhost:8080 | admin / admin |
| **Superset** | http://localhost:8088 | admin / admin |
| **Grafana** | http://localhost:3000 | admin / admin |
| **MinIO** | http://localhost:9001 | minioadmin / minioadmin |

---

## ğŸ“ Estrutura do Projeto

```
sp-trans-pipeline/
â”œâ”€â”€ config/                 # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ grafana/
â”œâ”€â”€ dags/                   # DAGs Airflow (7)
â”œâ”€â”€ sql/                    # Scripts SQL (8)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/            # MÃ³dulos base
â”‚   â”œâ”€â”€ ingestion/         # IngestÃ£o de dados
â”‚   â”œâ”€â”€ processing/        # Jobs Spark
â”‚   â”œâ”€â”€ serving/           # Serving layer
â”‚   â””â”€â”€ monitoring/        # Monitoramento
â”œâ”€â”€ tests/                 # Testes
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ integration/
â”œâ”€â”€ docs/                  # DocumentaÃ§Ã£o
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â””â”€â”€ requirements.txt
```

---

## ğŸ”„ Pipeline Flow

### 1. IngestÃ£o (Bronze)
- **API Olho Vivo**: A cada 3 minutos
- **GTFS EstÃ¡tico**: Diariamente Ã s 02:00
- **Formato**: Parquet particionado

### 2. TransformaÃ§Ã£o (Silver)
- **Limpeza**: RemoÃ§Ã£o de nulos, outliers
- **NormalizaÃ§Ã£o**: Estrutura tabular
- **Enriquecimento**: Geocoding, telemetria
- **Formato**: Delta Lake

### 3. AgregaÃ§Ã£o (Gold)
- **MÃ©tricas HorÃ¡rias**: Por linha
- **SumarizaÃ§Ã£o DiÃ¡ria**: Sistema completo
- **KPIs**: Velocidade, headway, congestÃ£o
- **Formato**: Delta Lake

### 4. Serving (PostgreSQL)
- **Load**: A cada 10 minutos
- **OtimizaÃ§Ã£o**: Ãndices, MVs, partiÃ§Ãµes
- **Consumo**: Dashboards, APIs

---

## ğŸ“Š KPIs Calculados

### Operacionais
- ğŸšŒ Frota ativa por linha
- â±ï¸ Headway (intervalo entre veÃ­culos)
- ğŸ¯ Taxa de pontualidade
- ğŸ“ˆ Cobertura de serviÃ§o

### Performance
- âš¡ Velocidade mÃ©dia
- ğŸš¦ Ãndice de congestionamento
- ğŸ“ DistÃ¢ncia percorrida
- ğŸ”„ Reliability score

### Qualidade
- âœ… Data quality score
- ğŸ” Completude de dados
- ğŸ² Taxa de duplicatas
- â° Freshness

---

## ğŸ§ª Testes

```bash
# Todos os testes
make test

# Unit tests
make test-unit

# Integration tests
make test-integration

# Com coverage
make test-coverage
```

---

## ğŸ“š DocumentaÃ§Ã£o

DocumentaÃ§Ã£o completa em `/docs`:
- [Arquitetura](docs/01_architecture.md)
- [Setup Guide](docs/02_setup_guide.md)
- [Data Dictionary](docs/03_data_dictionary.md)
- [API Reference](docs/04_api_reference.md)
- [Troubleshooting](docs/05_troubleshooting.md)

---

## ğŸ”§ Comandos Ãšteis (Makefile)

```bash
# Setup inicial
make setup                 # ConfiguraÃ§Ã£o completa
make up                    # Iniciar todos serviÃ§os
make down                  # Parar todos serviÃ§os

# Database
make db-init              # Criar database
make db-migrate           # Executar migrations
make db-backup            # Backup completo

# Airflow
make airflow-init         # Inicializar Airflow
make airflow-trigger-all  # Trigger todos DAGs

# Spark
make spark-submit         # Submit job Spark
make spark-shell          # Spark shell interativo

# MinIO
make minio-create-buckets # Criar buckets
make minio-list          # Listar objetos

# Monitoramento
make logs                # Ver logs de todos serviÃ§os
make status              # Status dos serviÃ§os

# Limpeza
make clean               # Limpar dados temporÃ¡rios
make clean-all           # Reset completo
```

---

## ğŸ“ˆ MÃ©tricas & Monitoramento

### Prometheus Metrics
- `sptrans_pipeline_records_processed_total`
- `sptrans_pipeline_duration_seconds`
- `sptrans_pipeline_data_quality_score`
- `sptrans_pipeline_api_requests_total`

### Grafana Dashboards
1. **System Overview**: CPU, memÃ³ria, disco
2. **Pipeline Performance**: DuraÃ§Ã£o, throughput
3. **Data Quality**: Scores, validaÃ§Ãµes
4. **Business KPIs**: Frota, velocidade, headway

---

## ğŸ“ Conformidade AcadÃªmica

### Requisitos Atendidos âœ…
- âœ… Near real-time (< 3 minutos)
- âœ… Data Lake com mÃºltiplas camadas
- âœ… GTFS integrado
- âœ… Enriquecimento (geocoding)
- âœ… KPIs e mÃ©tricas
- âœ… Dashboards interativos
- âœ… 100% Open Source
- âœ… DocumentaÃ§Ã£o completa
- âœ… CÃ³digo fonte versionado

---

## ğŸ‘¨â€ğŸ’» Autor

**Rafael** (rafarpl)  
PÃ³s-GraduaÃ§Ã£o em Engenharia de Dados  
FIA/LABDATA - 2024

---

## ğŸ“ LicenÃ§a

MIT License - Veja [LICENSE](LICENSE) para detalhes

---

## ğŸ™ Agradecimentos

- **SPTrans** pelos dados pÃºblicos
- **FIA/LABDATA** pela orientaÃ§Ã£o
- **Professores** pelo feedback
- **Comunidade Open Source**

---

## ğŸ“ Suporte

- ğŸ› **Issues**: [GitHub Issues](https://github.com/rafarpl/sp-trans-pipeline/issues)
- ğŸ“§ **Email**: contato@exemplo.com
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/rafarpl/sp-trans-pipeline/discussions)

---

**â­ Se este projeto foi Ãºtil, considere dar uma estrela no GitHub!**
